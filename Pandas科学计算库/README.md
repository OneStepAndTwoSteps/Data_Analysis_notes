
# ğŸ“–pandasç”¨æ³•æ¢³ç†

## pandasä»‹ç»ï¼š
  åœ¨æ•°æ®åˆ†æå·¥ä½œä¸­ï¼ŒPandas çš„ä½¿ç”¨é¢‘ç‡æ˜¯å¾ˆé«˜çš„ï¼Œä¸€æ–¹é¢æ˜¯å› ä¸º Pandas æä¾›çš„åŸºç¡€æ•°æ®ç»“æ„ DataFrame ä¸ json çš„å¥‘åˆåº¦å¾ˆé«˜ï¼Œè½¬æ¢èµ·æ¥å°±å¾ˆæ–¹ä¾¿ã€‚
  å¦ä¸€æ–¹é¢ï¼Œå¦‚æœæˆ‘ä»¬æ—¥å¸¸çš„æ•°æ®æ¸…ç†å·¥ä½œä¸æ˜¯å¾ˆå¤æ‚çš„è¯ï¼Œä½ é€šå¸¸ç”¨å‡ å¥ Pandas ä»£ç å°±å¯ä»¥å¯¹æ•°æ®è¿›è¡Œè§„æ•´ã€‚

  Pandas å¯ä»¥è¯´æ˜¯åŸºäº NumPy æ„å»ºçš„å«æœ‰æ›´é«˜çº§æ•°æ®ç»“æ„å’Œåˆ†æèƒ½åŠ›çš„å·¥å…·åŒ…ã€‚åœ¨ NumPy ä¸­æ•°æ®ç»“æ„æ˜¯å›´ç»• ndarray å±•å¼€çš„ï¼Œé‚£ä¹ˆåœ¨ Pandas ä¸­çš„æ ¸å¿ƒæ•°æ®ç»“æ„æ˜¯ä»€ä¹ˆå‘¢ï¼Ÿ

  ä¸‹é¢ä¸»è¦ç»™ä½ è®²ä¸‹Series å’Œ DataFrame è¿™ä¸¤ä¸ªæ ¸å¿ƒæ•°æ®ç»“æ„ï¼Œä»–ä»¬åˆ†åˆ«ä»£è¡¨ç€ä¸€ç»´çš„åºåˆ—å’ŒäºŒç»´çš„è¡¨ç»“æ„ã€‚åŸºäºè¿™ä¸¤ç§æ•°æ®ç»“æ„ï¼ŒPandas å¯ä»¥å¯¹æ•°æ®è¿›è¡Œå¯¼å…¥ã€æ¸…æ´—ã€å¤„ç†ã€ç»Ÿè®¡å’Œè¾“å‡ºã€‚

## pandas.set_option é€‰é¡¹è®¾ç½®
  __å¯ä»¥è®¾ç½®pandasçš„å±æ€§ï¼Œæ¯”å¦‚æ‰“å°å‡ºæ¥æ•°æ®æ—¶æ˜¾ç¤ºå¤šå°‘åˆ—ï¼Œæ˜¾ç¤ºå¤šå®½ç­‰ç­‰ï¼Œå¯ä»¥ä¸€æ¬¡æ€§è®¾ç½®å¤šä¸ªæ ¼å¼å¦‚ä¸‹__
   
  è®¾ç½®pandasä¿ç•™å°æ•°ä½æ•°ä¸ºä¸‰ä½
  
    pd.set_option('display.float_format', lambda x: '%.3f' % x)
  
  é»˜è®¤æ˜¾ç¤ºåˆ—æ•°ï¼Œè¡Œæ•°,å½“è®¾ç½®ä¸ºNoneæ—¶ï¼Œè¡¨ç¤ºæ˜¾ç¤ºæ‰€æœ‰å†…å®¹
    
    pd.set_option('display.max_columns',5, 'display.max_rows', 100)
  
  è®¾ç½®pandasæ˜¾ç¤ºæ‰€æœ‰æ•°æ®å†…å®¹(ä¸éšè—æ•°æ®)ï¼š

  æ˜¾ç¤ºæ‰€æœ‰åˆ— (åˆ—ä¸­æœ‰çœç•¥çš„ä¸çœç•¥)

    pd.set_option('display.max_columns', None)
    
  __è§£å†³å¦‚ä¸‹é—®é¢˜ï¼š__

      11 12 13 ... 19 20
      21 22 23 ... 29 30
      31 32 33 ... 39 40
      41 42 43 ... 49 50

  æ˜¾ç¤ºæ‰€æœ‰è¡Œ (è¡Œä¸­æœ‰çœç•¥çš„ä¸çœç•¥)
  
    pd.set_option('display.max_rows', None)

  __è§£å†³å¦‚ä¸‹é—®é¢˜ï¼š__

      1 2 3
      4 5 6
      7 8 9
      ...
      100 101 102    
      
## æ•°æ®ç»“æ„Series å’Œ Dataframe

### Serie
  __Series æ˜¯ä¸ªå®šé•¿çš„å­—å…¸åºåˆ—__ ã€‚è¯´æ˜¯å®šé•¿æ˜¯å› ä¸ºåœ¨å­˜å‚¨çš„æ—¶å€™ï¼Œç›¸å½“äºä¸¤ä¸ª ndarrayï¼Œè¿™ä¹Ÿæ˜¯å’Œå­—å…¸ç»“æ„æœ€å¤§çš„ä¸åŒã€‚å› ä¸ºåœ¨å­—å…¸çš„ç»“æ„é‡Œï¼Œå…ƒç´ çš„ä¸ªæ•°æ˜¯ä¸å›ºå®šçš„ã€‚
  
  __Series çš„ä¸¤ä¸ªåŸºæœ¬å±æ€§__ æœ‰ä¸¤ä¸ªåŸºæœ¬å±æ€§ï¼šindex å’Œ valuesã€‚åœ¨ Series ç»“æ„ä¸­ï¼Œindex é»˜è®¤æ˜¯ 0,1,2,â€¦â€¦é€’å¢çš„æ•´æ•°åºåˆ—ï¼Œå½“ç„¶æˆ‘ä»¬ä¹Ÿå¯ä»¥è‡ªå·±æ¥æŒ‡å®šç´¢å¼•ï¼Œæ¯”å¦‚ index=[â€˜aâ€™, â€˜bâ€™, â€˜câ€™, â€˜dâ€™]ã€‚
  
  __ä¾‹å­ï¼š__
  
    import pandas as pd
    from pandas import Series, DataFrame
    x1 = Series([1,2,3,4])
    x2 = Series(data=[1,2,3,4], index=['a', 'b', 'c', 'd'])
    print x1
    print x2

  
  __è¿è¡Œç»“æœï¼š__
  
    0    1
    1    2
    2    3
    3    4
    dtype: int64
    a    1
    b    2
    c    3
    d    4
    dtype: int64
    
è¿™ä¸ªä¾‹å­ä¸­ï¼Œx1 ä¸­çš„ index é‡‡ç”¨çš„æ˜¯é»˜è®¤å€¼ï¼Œx2 ä¸­ index è¿›è¡Œäº†æŒ‡å®šã€‚æˆ‘ä»¬ä¹Ÿå¯ä»¥é‡‡ç”¨å­—å…¸çš„æ–¹å¼æ¥åˆ›å»º Seriesï¼Œæ¯”å¦‚ï¼š

__ä¾‹å­ï¼š__

    d = {'a':1, 'b':2, 'c':3, 'd':4}
    x3 = Series(d)
    print x3 

__è¿è¡Œç»“æœï¼š__
  
    a    1
    b    2
    c    3
    d    4
    dtype: int64

### DataFrame ç±»å‹æ•°æ®ç»“æ„ç±»ä¼¼æ•°æ®åº“è¡¨ã€‚

  å®ƒåŒ…æ‹¬äº†è¡Œç´¢å¼•å’Œåˆ—ç´¢å¼•ï¼Œæˆ‘ä»¬å¯ä»¥å°† DataFrame çœ‹æˆæ˜¯ç”±ç›¸åŒç´¢å¼•çš„ Series ç»„æˆçš„å­—å…¸ç±»å‹ã€‚
  
  æˆ‘ä»¬è™šæ„ä¸€ä¸ªè€ƒè¯•çš„åœºæ™¯ï¼Œæƒ³è¦è¾“å‡ºå‡ ä½è‹±é›„çš„è€ƒè¯•æˆç»©ï¼š
    
    import pandas as pd
    from pandas import Series, DataFrame
    data = {'Chinese': [66, 95, 93, 90,80],'English': [65, 85, 92, 88, 90],'Math': [30, 98, 96, 77, 90]}
    df1= DataFrame(data)
    df2 = DataFrame(data, index=['ZhangFei', 'GuanYu', 'ZhaoYun', 'HuangZhong', 'DianWei'], columns=['English', 'Math', 'Chinese'])
    print df1
    print df2

  åœ¨åé¢çš„æ¡ˆä¾‹ä¸­ï¼Œæˆ‘ä¸€èˆ¬ä¼šç”¨ df, df1, df2 è¿™äº›ä½œä¸º DataFrame æ•°æ®ç±»å‹çš„å˜é‡åï¼Œæˆ‘ä»¬ä»¥ä¾‹å­ä¸­çš„ df2 ä¸ºä¾‹ï¼Œ
  åˆ—ç´¢å¼•æ˜¯ [â€˜Englishâ€™, â€˜Mathâ€™, â€˜Chineseâ€™]ï¼Œè¡Œç´¢å¼•æ˜¯ [â€˜ZhangFeiâ€™, â€˜GuanYuâ€™, â€˜ZhaoYunâ€™, â€˜HuangZhongâ€™, â€˜DianWeiâ€™]ï¼Œæ‰€ä»¥ df2 çš„è¾“å‡ºæ˜¯ï¼š
  
  
                  English  Math  Chinese
    ZhangFei         65    30       66
    GuanYu           85    98       95
    ZhaoYun          92    96       93
    HuangZhong       88    77       90
    DianWei          90    90       80

åœ¨äº†è§£äº† Series å’Œ DataFrame è¿™ä¸¤ä¸ªæ•°æ®ç»“æ„åï¼Œæˆ‘ä»¬å°±ä»æ•°æ®å¤„ç†çš„æµç¨‹è§’åº¦ï¼Œæ¥çœ‹ä¸‹ä»–ä»¬çš„ä½¿ç”¨æ–¹æ³•ã€‚

Pandas å…è®¸ç›´æ¥ä» xlsxï¼Œcsv ç­‰æ–‡ä»¶ä¸­å¯¼å…¥æ•°æ®ï¼Œä¹Ÿå¯ä»¥è¾“å‡ºåˆ° xlsx, csv ç­‰æ–‡ä»¶ï¼Œéå¸¸æ–¹ä¾¿ã€‚
  
    import pandas as pd
    from pandas import Series, DataFrame
    score = DataFrame(pd.read_excel('data.xlsx'))
    score.to_excel('data1.xlsx')
    print score
  
éœ€è¦è¯´æ˜çš„æ˜¯ï¼Œåœ¨è¿è¡Œçš„è¿‡ç¨‹å¯èƒ½ä¼šå­˜åœ¨ç¼ºå°‘ xlrd å’Œ openpyxl åŒ…çš„æƒ…å†µï¼Œåˆ°æ—¶å€™å¦‚æœç¼ºå°‘äº†ï¼Œå¯ä»¥åœ¨å‘½ä»¤è¡Œæ¨¡å¼ä¸‹ä½¿ç”¨â€œpip installâ€å‘½ä»¤æ¥è¿›è¡Œå®‰è£…ã€‚

  
### æ•°æ®æ¸…æ´—
  æ•°æ®æ¸…æ´—æ˜¯æ•°æ®å‡†å¤‡è¿‡ç¨‹ä¸­å¿…ä¸å¯å°‘çš„ç¯èŠ‚ï¼ŒPandas ä¹Ÿä¸ºæˆ‘ä»¬æä¾›äº†æ•°æ®æ¸…æ´—çš„å·¥å…·ï¼Œåœ¨åé¢æ•°æ®æ¸…æ´—çš„ç« èŠ‚ä¸­ä¼šç»™ä½ åšè¯¦ç»†çš„ä»‹ç»ï¼Œè¿™é‡Œç®€å•ä»‹ç»ä¸‹ Pandas åœ¨æ•°æ®æ¸…æ´—ä¸­çš„ä½¿ç”¨æ–¹æ³•ã€‚
  
  è¿˜æ˜¯ä»¥ä¸Šé¢è¿™äº›è‹±é›„äººç‰©çš„æ•°æ®ä¸ºä¾‹ã€‚
  
    data = {'Chinese': [66, 95, 93, 90,80],'English': [65, 85, 92, 88, 90],'Math': [30, 98, 96, 77, 90]}
    df2 = DataFrame(data, index=['ZhangFei', 'GuanYu', 'ZhaoYun', 'HuangZhong', 'DianWei'], columns=['English', 'Math', 'Chinese'])

  åœ¨æ•°æ®æ¸…æ´—è¿‡ç¨‹ä¸­ï¼Œä¸€èˆ¬éƒ½ä¼šé‡åˆ°ä»¥ä¸‹è¿™å‡ ç§æƒ…å†µï¼Œä¸‹é¢æˆ‘æ¥ç®€å•ä»‹ç»ä¸€ä¸‹ã€‚
  
  __1. åˆ é™¤ DataFrame ä¸­çš„ä¸å¿…è¦çš„åˆ—æˆ–è¡Œï¼š__
  
  Pandas æä¾›äº†ä¸€ä¸ªä¾¿æ·çš„æ–¹æ³• drop() å‡½æ•°æ¥åˆ é™¤æˆ‘ä»¬ä¸æƒ³è¦çš„åˆ—æˆ–è¡Œã€‚æ¯”å¦‚æˆ‘ä»¬æƒ³æŠŠâ€œè¯­æ–‡â€è¿™åˆ—åˆ æ‰ã€‚
    
    df2 = df2.drop(columns=['Chinese'])

  æƒ³æŠŠâ€œå¼ é£â€è¿™è¡Œåˆ æ‰ã€‚
  
    df2 = df2.drop(index=['ZhangFei'])

  __2. é‡å‘½ååˆ—å columnsï¼Œè®©åˆ—è¡¨åæ›´å®¹æ˜“è¯†åˆ«ï¼š__
  
  å¦‚æœä½ æƒ³å¯¹ DataFrame ä¸­çš„ columns è¿›è¡Œé‡å‘½åï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨ rename(columns=new_names, inplace=True) å‡½æ•°ï¼Œæ¯”å¦‚æˆ‘æŠŠåˆ—å Chinese æ”¹æˆ YuWenï¼ŒEnglish æ”¹æˆ YingYuã€‚
  
    # inplaceï¼šåˆ·é€‰è¿‡ç¼ºå¤±å€¼å¾—æ–°æ•°æ®æ˜¯å­˜ä¸ºå‰¯æœ¬è¿˜æ˜¯ç›´æ¥åœ¨åŸæ•°æ®ä¸Šè¿›è¡Œä¿®æ”¹ã€‚
    df2.rename(columns={'Chinese': 'YuWen', 'English': 'Yingyu'}, inplace = True)

  __3. å»é‡å¤çš„å€¼ï¼š__
    æ•°æ®é‡‡é›†å¯èƒ½å­˜åœ¨é‡å¤çš„è¡Œï¼Œè¿™æ—¶åªè¦ä½¿ç”¨ drop_duplicates() å°±ä¼šè‡ªåŠ¨æŠŠé‡å¤çš„è¡Œå»æ‰ã€‚
  
      df = df.drop_duplicates() # å»é™¤é‡å¤è¡Œ

  __4. æ ¼å¼é—®é¢˜ï¼š__
    è¿™æ˜¯ä¸ªæ¯”è¾ƒå¸¸ç”¨çš„æ“ä½œï¼Œå› ä¸ºå¾ˆå¤šæ—¶å€™æ•°æ®æ ¼å¼ä¸è§„èŒƒï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ astype å‡½æ•°æ¥è§„èŒƒæ•°æ®æ ¼å¼ï¼Œæ¯”å¦‚æˆ‘ä»¬æŠŠ Chinese å­—æ®µçš„å€¼æ”¹æˆ str ç±»å‹ï¼Œæˆ–è€… int64 å¯ä»¥è¿™ä¹ˆå†™ï¼š
  
      df2['Chinese'].astype('str') 
      df2['Chinese'].astype(np.int64) 


### æ•°æ®é—´çš„ç©ºæ ¼

  æœ‰æ—¶å€™æˆ‘ä»¬å…ˆæŠŠæ ¼å¼è½¬æˆäº† str ç±»å‹ï¼Œæ˜¯ä¸ºäº†æ–¹ä¾¿å¯¹æ•°æ®è¿›è¡Œæ“ä½œï¼Œè¿™æ—¶æƒ³è¦åˆ é™¤æ•°æ®é—´çš„ç©ºæ ¼ï¼Œæˆ‘ä»¬å°±å¯ä»¥ä½¿ç”¨ strip å‡½æ•°ï¼š
  
    # åˆ é™¤å·¦å³ä¸¤è¾¹ç©ºæ ¼
    df2['Chinese']=df2['Chinese'].map(str.strip)
    # åˆ é™¤å·¦è¾¹ç©ºæ ¼
    df2['Chinese']=df2['Chinese'].map(str.lstrip)
    # åˆ é™¤å³è¾¹ç©ºæ ¼
    df2['Chinese']=df2['Chinese'].map(str.rstrip)

  å¦‚æœæ•°æ®é‡Œæœ‰æŸä¸ªç‰¹æ®Šçš„ç¬¦å·ï¼Œæˆ‘ä»¬æƒ³è¦åˆ é™¤æ€ä¹ˆåŠï¼ŸåŒæ ·å¯ä»¥ä½¿ç”¨ strip å‡½æ•°ï¼Œæ¯”å¦‚ Chinese å­—æ®µé‡Œæœ‰ç¾å…ƒç¬¦å·ï¼Œæˆ‘ä»¬æƒ³æŠŠè¿™ä¸ªåˆ æ‰ï¼Œå¯ä»¥è¿™ä¹ˆå†™ï¼š

    df2['Chinese']=df2['Chinese'].str.strip('$')


__å¤§å°å†™è½¬æ¢ï¼š__
  
  å¤§å°å†™æ˜¯ä¸ªæ¯”è¾ƒå¸¸è§çš„æ“ä½œï¼Œæ¯”å¦‚äººåã€åŸå¸‚åç­‰çš„ç»Ÿä¸€éƒ½å¯èƒ½ç”¨åˆ°å¤§å°å†™çš„è½¬æ¢ï¼Œåœ¨ Python é‡Œç›´æ¥ä½¿ç”¨ upper(), lower(), title() å‡½æ•°ï¼Œæ–¹æ³•å¦‚ä¸‹ï¼š
  
    # å…¨éƒ¨å¤§å†™
    df2.columns = df2.columns.str.upper()
    # å…¨éƒ¨å°å†™
    df2.columns = df2.columns.str.lower()
    # é¦–å­—æ¯å¤§å†™
    df2.columns = df2.columns.str.title()

  
__æŸ¥æ‰¾ç©ºå€¼ï¼š__

  æ•°æ®é‡å¤§çš„æƒ…å†µä¸‹ï¼Œæœ‰äº›å­—æ®µå­˜åœ¨ç©ºå€¼ NaN çš„å¯èƒ½ï¼Œè¿™æ—¶å°±éœ€è¦ä½¿ç”¨ Pandas ä¸­çš„ isnull å‡½æ•°è¿›è¡ŒæŸ¥æ‰¾ã€‚æ¯”å¦‚ï¼Œæˆ‘ä»¬è¾“å…¥ä¸€ä¸ªæ•°æ®è¡¨å¦‚ä¸‹ï¼š
    
    å§“å     è¯­æ–‡     è‹±è¯­     æ•°å­¦
    
    å¼ é£     66       65        
    
    å…³ç¾½     95       85       98   
  
    èµµäº‘     95       92       96   
    
    é»„å¿      90       88       77   
  
    å…¸éŸ¦     80       90       90   
  
  
  
  å¦‚æœæˆ‘ä»¬æƒ³çœ‹ä¸‹å“ªä¸ªåœ°æ–¹å­˜åœ¨ç©ºå€¼ NaNï¼Œå¯ä»¥é’ˆå¯¹æ•°æ®è¡¨ dfè¿›è¡Œdf.isnull():ç»“æœå¦‚ä¸‹

        å§“å      è¯­æ–‡     è‹±è¯­     æ•°å­¦
     0  False    False    False    True   
     1  False    False    False    False   
     2  False    False    False    False   
     3  False    False    False    False   
     4  False    False    False    False   

  
  å¦‚æœæˆ‘æƒ³çŸ¥é“å“ªåˆ—å­˜åœ¨ç©ºå€¼ï¼Œå¯ä»¥ä½¿ç”¨ df.isnull().any()ï¼Œç»“æœå¦‚ä¸‹ï¼š
  
    å§“å     False
    è¯­æ–‡     False
    è‹±è¯­     False
    æ•°å­¦     True
  
  
  __ä½¿ç”¨ apply å‡½æ•°å¯¹æ•°æ®è¿›è¡Œæ¸…æ´—ï¼š__
  
    apply å‡½æ•°æ˜¯ Pandas ä¸­è‡ªç”±åº¦éå¸¸é«˜çš„å‡½æ•°ï¼Œä½¿ç”¨é¢‘ç‡ä¹Ÿéå¸¸é«˜ã€‚
    æ¯”å¦‚æˆ‘ä»¬æƒ³å¯¹ name åˆ—çš„æ•°å€¼éƒ½è¿›è¡Œå¤§å†™è½¬åŒ–å¯ä»¥ç”¨ï¼š
  
      df['name'] = df['name'].apply(str.upper)
      
    æˆ‘ä»¬ä¹Ÿå¯ä»¥å®šä¹‰ä¸ªå‡½æ•°ï¼Œåœ¨ apply ä¸­è¿›è¡Œä½¿ç”¨ã€‚æ¯”å¦‚å®šä¹‰ double_df å‡½æ•°æ˜¯å°†åŸæ¥çš„æ•°å€¼ *2 è¿›è¡Œè¿”å›ã€‚ç„¶åå¯¹ df1 ä¸­çš„â€œè¯­æ–‡â€åˆ—çš„æ•°å€¼è¿›è¡Œ *2 å¤„ç†ï¼Œå¯ä»¥å†™æˆï¼š
  
      def double_df(x):
           return 2*x
      df1[u'è¯­æ–‡'] = df1[u'è¯­æ–‡'].apply(double_df)

    æˆ‘ä»¬ä¹Ÿå¯ä»¥å®šä¹‰æ›´å¤æ‚çš„å‡½æ•°ï¼Œæ¯”å¦‚å¯¹äº DataFrameï¼Œæˆ‘ä»¬æ–°å¢ä¸¤åˆ—ï¼Œå…¶ä¸­â€™new1â€™åˆ—æ˜¯â€œè¯­æ–‡â€å’Œâ€œè‹±è¯­â€æˆç»©ä¹‹å’Œçš„ m å€ï¼Œ'new2â€™åˆ—æ˜¯â€œè¯­æ–‡â€å’Œâ€œè‹±è¯­â€æˆç»©ä¹‹å’Œçš„ n å€ï¼Œæˆ‘ä»¬å¯ä»¥è¿™æ ·å†™ï¼š
      
        def plus(df,n,m):
          df['new1'] = (df[u'è¯­æ–‡']+df[u'è‹±è¯­']) * m
          df['new2'] = (df[u'è¯­æ–‡']+df[u'è‹±è¯­']) * n
          return df
        df1 = df1.apply(plus,axis=1,args=(2,3,))

    å…¶ä¸­ axis=1 ä»£è¡¨æŒ‰ç…§åˆ—ä¸ºè½´è¿›è¡Œæ“ä½œï¼Œaxis=0 ä»£è¡¨æŒ‰ç…§è¡Œä¸ºè½´è¿›è¡Œæ“ä½œï¼Œargs æ˜¯ä¼ é€’çš„ä¸¤ä¸ªå‚æ•°ï¼Œå³ n=2, m=3ï¼Œåœ¨ plus å‡½æ•°ä¸­ä½¿ç”¨åˆ°äº† n å’Œ mï¼Œä»è€Œç”Ÿæˆæ–°çš„ dfã€‚
  
__è‡ªå®šä¹‰å‡½æ•°apply__
 
      def search_hundredth(train_content):
          hundredth=train_content.loc[99]
          return hundredth

      search_func=train_content.apply(search_hundredth)
      print(search_func)

  ### æ•°æ®ç»Ÿè®¡
  
    åœ¨æ•°æ®æ¸…æ´—åï¼Œæˆ‘ä»¬å°±è¦å¯¹æ•°æ®è¿›è¡Œç»Ÿè®¡äº†ã€‚Pandas å’Œ NumPy ä¸€æ ·ï¼Œéƒ½æœ‰å¸¸ç”¨çš„ç»Ÿè®¡å‡½æ•°ï¼Œå¦‚æœé‡åˆ°ç©ºå€¼ NaNï¼Œä¼šè‡ªåŠ¨æ’é™¤ã€‚
    å¸¸ç”¨çš„ç»Ÿè®¡å‡½æ•°åŒ…æ‹¬ï¼š
    ä»¥ä¸‹å‡½æ•°å¯ä»¥æŒ‡å®šè®¡ç®—çš„axisä¸ºè¡Œè¿˜æ˜¯åˆ—ï¼Œé»˜è®¤ä¸ºè¡Œ(å°±æ˜¯æŸä¸€åˆ—ä¸­çš„æ¯ä¸€è¡Œç‰¹å¾) axis=0ã€‚æ³¨æ„å¦‚æœè®¡ç®—æ‰€åœ¨æŸä¸€åˆ—/è¡Œä¸­å­˜åœ¨å­—ç¬¦ï¼Œåˆ™è¯¥åˆ—/è¡Œå°†ä¸è¿›è¡Œè®¡ç®—
 
      count()     ç»Ÿè®¡ä¸ªæ•°ï¼Œç©ºå€¼NaNä¸è®¡ç®—
      describe()  ä¸€æ¬¡æ€§è¾“å‡ºå¤šä¸ªç»Ÿè®¡æŒ‡æ ‡ï¼ŒåŒ…æ‹¬ï¼šcount,mean,std,min,max ç­‰
      min()       æœ€å°å€¼
      max()       æœ€å¤§å€¼
      sum()       æ€»å’Œ
      mean()      å¹³å‡å€¼
      median()    ä¸­ä½æ•°
      var()       æ–¹å·®
      std()       æ ‡å‡†å·®
      argmin()    ç»Ÿè®¡æœ€å°å€¼çš„ç´¢å¼•ä½ç½®
      argmax()    ç»Ÿè®¡æœ€å¤§å€¼çš„ç´¢å¼•ä½ç½®
      idxmin()    ç»Ÿè®¡æœ€å°å€¼çš„ç´¢å¼•å€¼
      idxmax()    ç»Ÿè®¡æœ€å¤§å€¼çš„ç´¢å¼•å€¼
      
      
   è¡¨æ ¼ä¸­æœ‰ä¸€ä¸ª describe() å‡½æ•°ï¼Œç»Ÿè®¡å‡½æ•°åƒåƒä¸‡ï¼Œdescribe() å‡½æ•°æœ€ç®€ä¾¿ã€‚å®ƒæ˜¯ä¸ªç»Ÿè®¡å¤§ç¤¼åŒ…ï¼Œå¯ä»¥å¿«é€Ÿè®©æˆ‘ä»¬å¯¹æ•°æ®æœ‰ä¸ªå…¨é¢çš„äº†è§£ã€‚ä¸‹é¢æˆ‘ç›´æ¥ä½¿ç”¨ df1.describe() è¾“å‡ºç»“æœä¸ºï¼š
      
        df1 = DataFrame({'name':['ZhangFei', 'GuanYu', 'a', 'b', 'c'], 'data1':range(5)})
        print df1.describe()
   __è¿è¡Œç»“æœ:__  
   
  ![Image text](https://raw.githubusercontent.com/OneStepAndTwoSteps/data_mining_analysis/master/static/describe.png)
        
   __æ•°æ®è¡¨åˆå¹¶__
    
   æœ‰æ—¶å€™æˆ‘ä»¬éœ€è¦å°†å¤šä¸ªæ¸ é“æºçš„å¤šä¸ªæ•°æ®è¡¨è¿›è¡Œåˆå¹¶ï¼Œä¸€ä¸ª DataFrame ç›¸å½“äºä¸€ä¸ªæ•°æ®åº“çš„æ•°æ®è¡¨ï¼Œé‚£ä¹ˆå¤šä¸ª DataFrame æ•°æ®è¡¨çš„åˆå¹¶å°±ç›¸å½“äºå¤šä¸ªæ•°æ®åº“çš„è¡¨åˆå¹¶ã€‚
    
   æ¯”å¦‚æˆ‘è¦åˆ›å»ºä¸¤ä¸ª DataFrameï¼š
    
      df1 = DataFrame({'name':['ZhangFei', 'GuanYu', 'a', 'b', 'c'], 'data1':range(5)})
      df2 = DataFrame({'name':['ZhangFei', 'GuanYu', 'A', 'B', 'C'], 'data2':range(5)})

   __1. åŸºäºæŒ‡å®šåˆ—è¿›è¡Œè¿æ¥__
      
   æ¯”å¦‚æˆ‘ä»¬å¯ä»¥åŸºäº name è¿™åˆ—è¿›è¡Œè¿æ¥ã€‚
    
        df3 = pd.merge(df1, df2, on='name')

   __è¿è¡Œç»“æœ:__ 
   
   ![Image text](https://raw.githubusercontent.com/OneStepAndTwoSteps/data_mining_analysis/master/static/1.png)
    
    
   __2. inner å†…è¿æ¥__
        
   inner å†…é“¾æ¥æ˜¯ merge åˆå¹¶çš„é»˜è®¤æƒ…å†µï¼Œinner å†…è¿æ¥å…¶å®ä¹Ÿå°±æ˜¯é”®çš„äº¤é›†ï¼Œåœ¨è¿™é‡Œ df1, df2 ç›¸åŒçš„é”®æ˜¯ nameï¼Œæ‰€ä»¥æ˜¯åŸºäº name å­—æ®µåšçš„è¿æ¥ï¼š
     
        df3 = pd.merge(df1, df2, how='inner')
   __è¿è¡Œç»“æœ:__ 
   
   ![Image text](https://raw.githubusercontent.com/OneStepAndTwoSteps/data_mining_analysis/master/static/2-1.png)
    
   __3. left å·¦è¿æ¥__
    
   å·¦è¿æ¥æ˜¯ä»¥ç¬¬ä¸€ä¸ª DataFrame ä¸ºä¸»è¿›è¡Œçš„è¿æ¥ï¼Œç¬¬äºŒä¸ª DataFrame ä½œä¸ºè¡¥å……ã€‚
        
          df3 = pd.merge(df1, df2, how='left')
   __è¿è¡Œç»“æœ:__
   
  ![Image text](https://raw.githubusercontent.com/OneStepAndTwoSteps/data_mining_analysis/master/static/3.png)

   __4. right å³è¿æ¥__
        
   å³è¿æ¥æ˜¯ä»¥ç¬¬äºŒä¸ª DataFrame ä¸ºä¸»è¿›è¡Œçš„è¿æ¥ï¼Œç¬¬ä¸€ä¸ª DataFrame ä½œä¸ºè¡¥å……ã€‚
      
        df3 = pd.merge(df1, df2, how='right')
   __è¿è¡Œç»“æœ:__
   
  ![Image text](https://raw.githubusercontent.com/OneStepAndTwoSteps/data_mining_analysis/master/static/4.png)

   __5. outer å¤–è¿æ¥__

   å¤–è¿æ¥ç›¸å½“äºæ±‚ä¸¤ä¸ª DataFrame çš„å¹¶é›†ã€‚
        
        df3 = pd.merge(df1, df2, how='outer')
   __è¿è¡Œç»“æœ:__
   
  ![Image text](https://raw.githubusercontent.com/OneStepAndTwoSteps/data_mining_analysis/master/static/5.png)
  
 ### å¦‚ä½•ç”¨ SQL æ–¹å¼æ‰“å¼€ Pandas
    
 Pandas çš„ DataFrame æ•°æ®ç±»å‹å¯ä»¥è®©æˆ‘ä»¬åƒå¤„ç†æ•°æ®è¡¨ä¸€æ ·è¿›è¡Œæ“ä½œï¼Œæ¯”å¦‚æ•°æ®è¡¨çš„å¢åˆ æ”¹æŸ¥ï¼Œéƒ½å¯ä»¥ç”¨ Pandas å·¥å…·æ¥å®Œæˆã€‚
 ä¸è¿‡ä¹Ÿä¼šæœ‰å¾ˆå¤šäººè®°ä¸ä½è¿™äº› Pandas çš„å‘½ä»¤ï¼Œç›¸æ¯”ä¹‹ä¸‹è¿˜æ˜¯ç”¨ SQL è¯­å¥æ›´ç†Ÿç»ƒï¼Œç”¨ SQL å¯¹æ•°æ®è¡¨è¿›è¡Œæ“ä½œæ˜¯æœ€æ–¹ä¾¿çš„ï¼Œå®ƒçš„è¯­å¥æè¿°å½¢å¼æ›´æ¥è¿‘æˆ‘ä»¬çš„è‡ªç„¶è¯­è¨€ã€‚
    
 äº‹å®ä¸Šï¼Œåœ¨ Python é‡Œå¯ä»¥ç›´æ¥ä½¿ç”¨ SQL è¯­å¥æ¥æ“ä½œ Pandasã€‚
    
 __è¿™é‡Œç»™ä½ ä»‹ç»ä¸ªå·¥å…·ï¼špandasqlã€‚__
    
 pandasql ä¸­çš„ä¸»è¦å‡½æ•°æ˜¯ sqldfï¼Œå®ƒæ¥æ”¶ä¸¤ä¸ªå‚æ•°ï¼šä¸€ä¸ª SQL æŸ¥è¯¢è¯­å¥ï¼Œè¿˜æœ‰ä¸€ç»„ç¯å¢ƒå˜é‡ globals() æˆ– locals()ã€‚è¿™æ ·æˆ‘ä»¬å°±å¯ä»¥åœ¨ Python é‡Œï¼Œç›´æ¥ç”¨ SQL è¯­å¥ä¸­å¯¹ DataFrame è¿›è¡Œæ“ä½œï¼Œä¸¾ä¸ªä¾‹å­ï¼šimport pandas as pd
     
  __ä¾‹å­ï¼š__
    
      from pandas import DataFrame
      from pandasql import sqldf, load_meat, load_births
      df1 = DataFrame({'name':['ZhangFei', 'GuanYu', 'a', 'b', 'c'], 'data1':range(5)})
      pysqldf = lambda sql: sqldf(sql, globals())
      sql = "select * from df1 where name ='ZhangFei'"
      print pysqldf(sql)

    
  __è¿è¡Œç»“æœï¼š__
  
      data1      name
      0      0  ZhangFei

  ä¸Šé¢è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬æ˜¯å¯¹â€œname='ZhangFeiâ€â€œçš„è¡Œè¿›è¡Œäº†è¾“å‡ºã€‚å½“ç„¶ä½ ä¼šçœ‹åˆ°æˆ‘ä»¬ç”¨åˆ°äº† lambdaï¼Œlambda åœ¨ python ä¸­ç®—æ˜¯ä½¿ç”¨é¢‘ç‡å¾ˆé«˜çš„ï¼Œé‚£ lambda æ˜¯ç”¨æ¥åšä»€ä¹ˆçš„å‘¢ï¼Ÿ
  å®ƒå®é™…ä¸Šæ˜¯ç”¨æ¥å®šä¹‰ä¸€ä¸ªåŒ¿åå‡½æ•°çš„ï¼Œå…·ä½“çš„ä½¿ç”¨å½¢å¼ä¸ºï¼š
  
      lambda argument_list: expression

  
  
  è¿™é‡Œ argument_list æ˜¯å‚æ•°åˆ—è¡¨ï¼Œexpression æ˜¯å…³äºå‚æ•°çš„è¡¨è¾¾å¼ï¼Œä¼šæ ¹æ® expression è¡¨è¾¾å¼è®¡ç®—ç»“æœè¿›è¡Œè¾“å‡ºè¿”å›ã€‚
  
  åœ¨ä¸Šé¢çš„ä»£ç ä¸­ï¼Œæˆ‘ä»¬å®šä¹‰äº†ï¼š
  
    pysqldf = lambda sql: sqldf(sql, globals())

  åœ¨è¿™ä¸ªä¾‹å­é‡Œï¼Œè¾“å…¥çš„å‚æ•°æ˜¯ sqlï¼Œè¿”å›çš„ç»“æœæ˜¯ sqldf å¯¹ sql çš„è¿è¡Œç»“æœï¼Œå½“ç„¶ sqldf ä¸­ä¹Ÿè¾“å…¥äº† globals å…¨å±€å‚æ•°ï¼Œå› ä¸ºåœ¨ sql ä¸­æœ‰å¯¹å…¨å±€å‚æ•° df1 çš„ä½¿ç”¨ã€‚
  
  ### è¯»å–æ–‡ä»¶é‡Œçš„å†…å®¹
  ä»¥csvçš„æ ¼å¼è¯»å–æ–‡ä»¶é‡Œçš„å†…å®¹
    
    train_content=pd.read_csv("train.csv")
  
  ä»¥xlsçš„æ ¼å¼è¯»å–æ–‡ä»¶é‡Œçš„å†…å®¹
    
    train_content=pd.read_excel("train.xls")
    
  æ˜¾ç¤ºpd_contentçš„å‰é¢ä¸‰è¡Œ(ä¸åŒ…æ‹¬åˆ—åå­—)  
     
     print(train_content.head(3)
  
  pivot_tableå‡½æ•°
    
  pivot_tableæœ‰å››ä¸ªæœ€é‡è¦çš„å‚æ•°indexã€valuesã€columnsã€aggfunc

  index     indexä»£è¡¨ç´¢å¼•ï¼Œæ¯ä¸ªpivot_tableå¿…é¡»æ‹¥æœ‰ä¸€ä¸ªindexã€‚
  Values    Valueså¯ä»¥å¯¹éœ€è¦çš„è®¡ç®—æ•°æ®è¿›è¡Œç­›é€‰
  Aggfunc   aggfuncå‚æ•°å¯ä»¥è®¾ç½®æˆ‘ä»¬å¯¹æ•°æ®èšåˆæ—¶è¿›è¡Œçš„å‡½æ•°æ“ä½œã€‚å½“æˆ‘ä»¬æœªè®¾ç½®aggfuncæ—¶ï¼Œå®ƒé»˜è®¤aggfunc='mean'è®¡ç®—å‡å€¼ï¼Œå¯ä»¥è®¾ç½®å¤šä¸ª å¦‚ï¼š
            [aggfunc=[np.sum,np.mean]] æ­¤æ—¶ä¼šæ˜¾ç¤ºnp.sumå’Œnp.meanç»Ÿè®¡å‡ºæ¥çš„æ•°æ®ã€‚
            
  Columns   Columnsç±»ä¼¼Indexå¯ä»¥è®¾ç½®åˆ—å±‚æ¬¡å­—æ®µï¼Œå®ƒä¸æ˜¯ä¸€ä¸ªå¿…è¦å‚æ•°ï¼Œä½œä¸ºä¸€ç§åˆ†å‰²æ•°æ®çš„å¯é€‰æ–¹å¼ã€‚

      #ä»¥ Pclass(èˆ¹èˆ±)ä¸ºç´¢å¼• æŸ¥çœ‹ä¸åŒèˆ¹èˆ±äººå‘˜çš„å¹³å‡å­˜æ´»ç‡Survivedã€‚
      train_survived=train_content.pivot_table(index="Pclass",values="Survived")
      
      # æŸ¥çœ‹ä¸åŒèˆ¹èˆ±çš„æ”¶è´¹å‡å€¼æ˜¯å¤šå°‘
      train_age_fare=train_content.pivot_table(index="Pclass",values=["Age","Fare"])
      
      # æŸ¥çœ‹ä¸åŒèˆ¹èˆ±äººå‘˜çš„çš„äººå‡å¹´é¾„
      train_survived=train_content.pivot_table(index="Pclass",values="Age")
  
  ### icolå’Œcol å–èŒƒå›´
    
   ilocå’Œlocçš„åŒºåˆ«æ˜¯ ilocåªèƒ½è·Ÿæ•´æ•°ï¼Œè€Œlocå¯ä»¥è·Ÿæ•°å­—
   
     print(train_content.iloc[83,3])     #æ‰¾çš„æ˜¯é™¤titleä»¥å¤–çš„ç¬¬84è¡Œï¼Œå› ä¸ºæ•°ç»„é»˜è®¤æ˜¯ä»0å¼€å§‹å‘ä¸Šå¢é•¿çš„
     print(train_content.iloc[82:83,3:5]) #å»å°¾çš„83ä¸åŒ…æ‹¬ 5ä¸åŒ…æ‹¬
     print(train_content.iloc[82:84,3:6]) #å»å°¾çš„83ä¸åŒ…æ‹¬ 5ä¸åŒ…æ‹¬

     print(train_content.loc[83,"Age"])
     print(train_content.loc[82:83,"Name":"Age"])   #è¿˜å¯ä»¥è·ŸèŒƒå›´

### å°†Pandasä¸­çš„DataFrameç±»å‹è½¬æ¢æˆNumpyä¸­arrayç±»å‹çš„ä¸‰ç§æ–¹æ³•
  dataframe è½¬åˆ—è¡¨  
      
      
1ã€ä½¿ç”¨DataFrameä¸­çš„valuesæ–¹æ³•

    df.values
  
2ã€ä½¿ç”¨DataFrameä¸­çš„as_matrix()æ–¹æ³•

    df.as_matrix()

3ã€ä½¿ç”¨Numpyä¸­çš„arrayæ–¹æ³•

    np.array(df)

### pandas.mode() 

__è¿”å›å‡ºç°é¢‘ç‡æœ€é«˜çš„å€¼ é»˜è®¤ axis=0ï¼Œå³æ¯ä¸€ç‰¹å¾ä¸­å‡ºç°æœ€é«˜çš„å€¼ é»˜è®¤å¿½ç•¥NAå€¼ï¼Œå¦‚æœæƒ³å°†NAå€¼è®¡ç®—è¿›å»å¯ä»¥ä½¿ç”¨ dropna=False__

__æ³¨æ„ï¼šå¦‚æœå­˜åœ¨é¢‘ç‡ç›¸åŒçš„å€¼ä¼šè¿”å›ä¸¤ä¸ªå€¼__

__æ•°æ®:__

    >>> df = pd.DataFrame([('bird', 2, 2),
    ...                    ('mammal', 4, np.nan),
    ...                    ('arthropod', 8, 0),
    ...                    ('bird', 2, np.nan)],
    ...                   index=('falcon', 'horse', 'spider', 'ostrich'),
    ...                   columns=('species', 'legs', 'wings'))
    >>> df
              species  legs  wings
    falcon        bird     2    2.0
    horse       mammal     4    NaN
    spider   arthropod     8    0.0
    ostrich       bird     2    NaN  

__ä¾‹å­1__

    >>> df.mode()
      species  legs  wings
    0    bird   2.0    0.0
    1     NaN   NaN    2.0

__ä¾‹å­2__

    >>> df.mode(dropna=False)
      species  legs  wings
    0    bird     2    NaN


### pandas.DataFrame.fillna ç”¨æŒ‡å®šçš„æ–¹æ³•å¡«å……NA/NaN

__DataFrame.fillnaï¼ˆvalue = Noneï¼Œmethod = Noneï¼Œaxis = Noneï¼Œinplace = Falseï¼Œlimit = Noneï¼Œdowncast = Noneï¼Œ** kwargs ï¼‰__
        
  value ï¼š æ ‡é‡ï¼Œå­—å…¸ï¼Œç³»åˆ—æˆ–DataFrameç”¨äºå¡«å……å­”çš„å€¼ï¼ˆä¾‹å¦‚0ï¼‰ï¼Œæˆ–è€…ç”¨äºæŒ‡å®šæ¯ä¸ªç´¢å¼•ï¼ˆå¯¹äºSeriesï¼‰æˆ–åˆ—ï¼ˆå¯¹äºDataFrameï¼‰ä½¿ç”¨å“ªä¸ªå€¼çš„Dict /Series / DataFrameã€‚ï¼ˆä¸ä¼šå¡«å†™dict / Series / DataFrameä¸­çš„å€¼ï¼‰ã€‚è¯¥å€¼ä¸èƒ½æ˜¯åˆ—è¡¨ã€‚
                 
  method :  {'backfill'ï¼Œ'bfill'ï¼Œ'pad'ï¼Œ'ffill'ï¼ŒNone}ï¼Œé»˜è®¤æ—    ç”¨äºå¡«å……é‡æ–°ç´¢å¼•çš„å¡«å……å­”çš„æ–¹æ³•ç³»åˆ—å¡«å……/å¡«å……
              
  axis : {0æˆ–'ç´¢å¼•'ï¼Œ1æˆ–'åˆ—'}
  
  ä¾‹å­ï¼š
  
      >>> df = pd.DataFrame([[np.nan, 2, np.nan, 0],
      ...                    [3, 4, np.nan, 1],
      ...                    [np.nan, np.nan, np.nan, 5],
      ...                    [np.nan, 3, np.nan, 4]],
      ...                    columns=list('ABCD'))
      >>> df
           A    B   C  D
      0  NaN  2.0 NaN  0
      1  3.0  4.0 NaN  1
      2  NaN  NaN NaN  5
      3  NaN  3.0 NaN  4

   __ç”¨0æ›¿æ¢æ‰€æœ‰NaNå…ƒç´ __
   
      >>> df.fillna(0)
          A   B   C   D
      0   0.0 2.0 0.0 0
      1   3.0 4.0 0.0 1
      2   0.0 0.0 0.0 5
      3   0.0 3.0 0.0 4

   __æˆ‘ä»¬è¿˜å¯ä»¥å‘å‰æˆ–å‘åä¼ æ’­éç©ºå€¼ã€‚__

    >>> df.fillna(method='ffill')
        A   B   C   D
    0   NaN 2.0 NaN 0
    1   3.0 4.0 NaN 1
    2   3.0 4.0 NaN 5
    3   3.0 3.0 NaN 4

   __å°†â€œAâ€ï¼Œâ€œBâ€ï¼Œâ€œCâ€å’Œâ€œDâ€åˆ—ä¸­çš„æ‰€æœ‰NaNå…ƒç´ åˆ†åˆ«æ›¿æ¢ä¸º0,1,2å’Œ3ã€‚__

    >>> values = {'A': 0, 'B': 1, 'C': 2, 'D': 3}
    >>> df.fillna(value=values)
        A   B   C   D
    0   0.0 2.0 2.0 0
    1   3.0 4.0 2.0 1
    2   0.0 1.0 2.0 5
    3   0.0 3.0 2.0 4
    
  __åªæ›¿æ¢ç¬¬ä¸€ä¸ªNaNå…ƒç´ ã€‚__

    >>> df.fillna(value=values, limit=1)
        A   B   C   D
    0   0.0 2.0 2.0 0
    1   3.0 4.0 NaN 1
    2   NaN 1.0 NaN 5
    3   NaN 3.0 NaN 4
    
    
  ### pandas.DataFrame.groupby   
  
  __groupbyæ“ä½œæ¶‰åŠæ‹†åˆ†å¯¹è±¡ï¼Œåº”ç”¨å‡½æ•°å’Œç»„åˆç»“æœçš„æŸç§ç»„åˆã€‚è¿™å¯ç”¨äºå¯¹è¿™äº›ç»„ä¸Šçš„å¤§é‡æ•°æ®å’Œè®¡ç®—æ“ä½œè¿›è¡Œåˆ†ç»„ã€‚__
  
  __ä½¿ç”¨groupbyè¿›è¡Œåˆ‡ç‰‡ä¹‹åï¼Œæˆ‘ä»¬å¦‚æœè¿›è¡Œæ“ä½œå…¶å®æ˜¯åœ¨é‚£ä¸ªåˆ‡ç‰‡(split)ä¸­è¿›è¡Œçš„æ“ä½œï¼Œè®¡ç®—å®Œæˆä¹‹åè¿”å›åˆå¹¶ç»“æœ(Combine) å¦‚å›¾ï¼š__

  ![Image_text]('https://raw.githubusercontent.com/OneStepAndTwoSteps/data_mining_analysis/master/static/pandas/2.png')


  __groupbyå‡½æ•° ä¾‹å­1__

    import pandas as pd
    import numpy as np

    dict_obj = {'key1' : ['a', 'b', 'a', 'b', 
                          'a', 'b', 'a', 'a'],
                'key2' : ['one', 'one', 'two', 'three',
                          'two', 'two', 'one', 'three'],
                'data1': np.random.randn(8),
                'data2': np.random.randn(8)}
    df_obj = pd.DataFrame(dict_obj)
    print(df_obj)

  __outï¼š__

      key1   key2     data1     data2
      0    a    one -0.109110  0.528666
      1    b    one -0.746051  1.994562
      2    a    two  2.685447  1.672294
      3    b  three  0.546663 -0.970285
      4    a    two -0.859890 -0.964093
      5    b    two -0.347244  0.146132
      6    a    one  0.254899  0.830872
      7    a  three -0.958547 -2.016811


  __dataframeæ ¹æ®key1è¿›è¡Œåˆ†ç»„__                                                                                                                                                                                                                                                           
    grouped1=df_obj.groupby('key1')

    [x for x in grouped1]


    [('a',   key1   key2     data1     data2
      0       a    one -0.109110  0.528666
      2       a    two  2.685447  1.672294
      4       a    two -0.859890 -0.964093
      6       a    one  0.254899  0.830872
      7       a  three -0.958547 -2.016811), ('b',   key1   key2     data1     data2
      1       b    one -0.746051  1.994562
      3       b  three  0.546663 -0.970285
      5       b    two -0.347244  0.146132)]

  __ä½¿ç”¨groupbyæŒ‡å®šå­—æ®µå†…å®¹è¿›è¡Œè¿ç®—__

  __å¦‚ï¼š__

    # æŒ‰ç…§ key1 è¿›è¡Œåˆ†ç»„ä»ä¸Šé¢çš„æ•°æ®ä¸­æˆ‘ä»¬å¯ä»¥å‘ç°åˆ†ä¸ºa,bä¸¤ç»„
    grouped = df.groupby(df['key1'])
    grouped.mean()

  __outï¼š__

    # è¿™é‡Œä½¿ç”¨ df['key1'] åšäº†åˆ†ç»„é”®ï¼Œå³æŒ‰ a å’Œ b è¿›è¡Œåˆ†ç»„ã€‚ä¸‹ä¾‹ä¸­æ²¡æœ‰æ˜¾ç¤º key2 åˆ—ï¼Œæ˜¯å› ä¸ºå…¶å€¼ä¸æ˜¯æ•°å­—ç±»å‹ï¼Œè¢« mean() æ–¹æ³•è‡ªåŠ¨å¿½è§†äº†
         data1	data2
    key1		
    a	0.202560	0.010185
    b	-0.182211	0.390136
      
  __å¦‚ï¼š__ 

    # ä»¥key1è¿›è¡Œåˆ†ç»„ï¼Œå°†data2å­—æ®µä¸­çš„å†…å®¹è¿›è¡Œæ±‚å’Œ
    grouped1=df_obj.groupby(['key1'])['data2'].sum()
    grouped1

  __outï¼š__

    key1
    a    0.050927
    b    1.170409
    Name: data2, dtype: float64

  __å¦‚ï¼š__ æ³¨æ„ä½¿ç”¨groupbyè¿›è¡Œå¤šåˆ—çš„ç»„åˆæ—¶ï¼Œé¡ºåºä¼šå½±å“æˆ‘ä»¬çš„åˆ†ç»„æ•ˆæœ å¦‚groupby(['key1','key2']) å’Œgroupby(['key2','key1'])å±•ç¤ºå‡ºæ¥çš„æ•ˆæœå°±ä¼šä¸åŒ

    # ä»¥key1ï¼Œå’Œkey2 è¿›è¡Œåˆ†ç»„ï¼Œå°†data2å­—æ®µä¸­çš„å†…å®¹è¿›è¡Œæ±‚å’Œ
    grouped1=df_obj.groupby(['key1','key2'])['data2'].sum()
    grouped1

  __outï¼š__

    key1  key2 
    a     one      1.359537
          three   -2.016811
          two      0.708200
    b     one      1.994562
          three   -0.970285
          two      0.146132


  __å¦‚ï¼š__

    # ä»¥Pclassè¿›è¡Œåˆ†ç»„ï¼Œå°†å­—æ®µä¸­'Pclass','Survived'çš„å†…å®¹è¿›è¡Œæ±‚å’Œ
    print(train_data.groupby(['Pclass'])['Pclass','Survived'].mean())
    
              Pclass    Survived
    Pclass                  
    1          1.0      0.629630
    2          2.0      0.472826
    3          3.0      0.242363
    
    print(train_data.groupby(['Pclass'])['Pclass'ï¼Œ'Survived','Age'].mean())

              Pclass    Survived        Age
    Pclass                             
    1          1.0      0.629630      37.048118
    2          2.0      0.472826      29.866958
    3          3.0      0.242363      26.403259


__åˆ†å±‚ç´¢å¼•__

    æˆ‘ä»¬å¯ä»¥ä½¿ç”¨levelå‚æ•°å¯¹ä¸åŒçº§åˆ«çš„å±‚æ¬¡ç´¢å¼•è¿›è¡Œåˆ†ç»„ï¼š

    >>> arrays = [['Falcon', 'Falcon', 'Parrot', 'Parrot'],
    ...           ['Capitve', 'Wild', 'Capitve', 'Wild']]
    >>> index = pd.MultiIndex.from_arrays(arrays, names=('Animal', 'Type'))
    >>> df = pd.DataFrame({'Max Speed' : [390., 350., 30., 20.]},
    ...                    index=index)
    >>> df
                    Max Speed
    Animal Type
    Falcon Capitve      390.0
           Wild         350.0
    Parrot Capitve       30.0
           Wild          20.0

    >>> df.groupby(level=0).mean()
            Max Speed
    Animal
    Falcon      370.0
    Parrot       25.0

    >>> df.groupby(level=1).mean()
             Max Speed
    Type
    Capitve      210.0
    Wild         185.0

__groupby å‡½æ•°çš„ä¸¤ä¸ªæ–¹æ³• .size() .count()__

å¯ä»¥ä½¿ç”¨ GroupBy å¯¹è±¡ï¼ˆä¸è®ºæ˜¯ DataFrameGroupBy è¿˜æ˜¯ SeriesGroupByï¼‰çš„ .size() æ–¹æ³•æŸ¥çœ‹åˆ†ç»„å¤§å°ï¼š

__.size å¦‚:__

    grouped.size()

__outï¼š__

    key1
    a       3
    b       2

__.count å¦‚ï¼š__

    grouped.count()

__outï¼š__

        key2	data1	data2
    key1			
    a	  5	    5	    5
    b	  3	    3	    3

__.size å’Œ .countçš„åŒºåˆ«ï¼š sizeè®¡æ•°æ—¶åŒ…å«NaNå€¼ï¼Œè€Œcountä¸åŒ…å«NaNå€¼__

  ### pandasæŒ‰è‹¥å¹²ä¸ªåˆ—çš„ç»„åˆæ¡ä»¶ç­›é€‰æ•°æ®
    #å–å¹´é¾„ç­‰äº26ï¼Œå¹¶ä¸”å­˜æ´»çš„æ•°æ®çš„æ•°é‡
    print(train_data[(train_data['Age']==29) & (train_data['Survived']==1)].count())

  ### pandasä¸€æ¬¡æ˜¾ç¤ºæŒ‡å®šçš„å¤šä¸ªæ ‡ç­¾ 
    #ä½¿ç”¨ [[ ]] ä¸¤å±‚åµŒå¥—æ‹¬å· æ¯”å¦‚ 
    print(train_data[['Survived','Age']])
    print("%s "%(new_user_data[new_user_data['èŠ‚']==section][['åå­—','çŸ¥è¯†ç‚¹']].values))

  ### pandas.Series.map
    
    æ ¹æ®è¾“å…¥çš„å¯¹åº”å…³ç³»æ˜ å°„ç³»åˆ—çš„å€¼ã€‚

    ç”¨äºå°†ç³»åˆ—ä¸­çš„æ¯ä¸ªå€¼æ›¿æ¢ä¸ºå¦ä¸€ä¸ªå€¼ï¼Œè¯¥å€¼å¯ä»¥ä»å‡½æ•°ï¼Œa dictæˆ–a æ´¾ç”ŸSeriesã€‚
  
  __ä¾‹å­ï¼š__
  
      >>> s = pd.Series(['cat', 'dog', np.nan, 'rabbit'])
      >>> s
      0      cat
      1      dog
      2      NaN
      3   rabbit
      dtype: object
  
  mapæ¥å—a dictæˆ–a Seriesã€‚é™¤édictå…·æœ‰é»˜è®¤å€¼ï¼ˆä¾‹å¦‚ï¼‰ï¼Œå¦åˆ™å°†dictè½¬æ¢ä¸ºæœªæ‰¾åˆ°çš„NaNå€¼defaultdictï¼š
  
      >>> s.map({'cat': 'kitten', 'dog': 'puppy'})
      0   kitten
      1    puppy
      2      NaN
      3      NaN
      dtype: object
      
  __å®ƒè¿˜æ¥å—ä¸€ä¸ªåŠŸèƒ½ï¼š__

    >>> s.map('I am a {}'.format)
    0       I am a cat
    1       I am a dog
    2       I am a nan
    3    I am a rabbit
    dtype: object
  
  ä¸ºé¿å…å°†å‡½æ•°åº”ç”¨äºç¼ºå¤±å€¼ï¼ˆå¹¶å°†å…¶ä¿ç•™ä¸º NaNï¼‰ï¼Œna_action='ignore'å¯ä»¥ä½¿ç”¨ï¼š

    >>> s.map('I am a {}'.format, na_action='ignore')
    0     I am a cat
    1     I am a dog
    2            NaN
    3  I am a rabbit
    dtype: object

  ### pandas to_dict

  __ä¾‹å­ï¼š__
    
    train_feature=vec.fit_transform(data.to_dict(orient='record'))

    orientå‚æ•°ä¸åŒä¼šæœ‰ä¸ä¸€æ ·çš„æ•ˆæœ 

    https://blog.csdn.net/m0_37804518/article/details/78444110


    
  ### python dataframe è·å¾— åˆ—åcolumns å’Œè¡Œåç§° index
   
    dfname._stat_axis.values.tolist()   ==  dfname.index.values.tolist()      # è¡Œåç§°
     
    
    dfname.columns.values.tolist()    # åˆ—åç§°

  ### python dataframe å½“æ— åˆ—åæ—¶è¿›è¡Œèµ‹å€¼åˆ—å

    # ä¸ºæ•°æ®å¢åŠ ä¸€è¡Œåˆ—å
    column=['user_id','åå­—','çŸ¥è¯†ç‚¹','èŠ‚','è¯¾ç¨‹','course_id']
    data.columns=column


  ### æ„é€ DataFrame

   __ä¾‹å­ï¼š__ å¦‚æœæƒ³è¦æ„é€ è¿™æ ·çš„dataframeï¼š

   <div align=center><img src="https://raw.githubusercontent.com/OneStepAndTwoSteps/data_mining_analysis/master/static/pandas/1.jpg"/></div> 

      import pandas as pd

      list1=[[1,2,3],[4,5,6],[7,8,9]]

      dict={'id':[1,2,3],'item':[[5,6,7,8],[1,2,3],[4,5,6]]}

      data=pd.DataFrame(data=dict,columns=['id','item'])

      print(data)


  ### pandas é”™è¯¯è­¦å‘Šï¼š

    åœ¨ä½¿ç”¨pd.read_csv()æ—¶ å‡ºç°äº†å¦‚ä¸‹çš„é”™è¯¯

      data=pd.read_csv(file_path)

      pandas.errors.ParserError: Error tokenizing data. C error: Expected 20 fields in line 4, saw 21

  __è§£å†³æ–¹æ¡ˆ1ï¼š__ åŠ ä¸Šåˆ†éš”ç¬¦ sep 

      data=pd.read_csv(file_path,sep='\t')

  __è§£å†³æ–¹æ¡ˆ2ï¼š__ å¿½ç•¥é”™è¯¯çš„è¡Œ

      data=pd.read_csv(file_path,error_bad_lines=False)

  


  ### æ•°æ®çš„ååº¦å’Œå³°åº¦

  __df.skew()  ååº¦__

    Definition:æ˜¯æè¿°æ•°æ®åˆ†å¸ƒå½¢æ€çš„ç»Ÿè®¡é‡ï¼Œå…¶æè¿°çš„æ˜¯æŸæ€»ä½“å–å€¼åˆ†å¸ƒçš„å¯¹ç§°æ€§ï¼Œç®€å•æ¥è¯´å°±æ˜¯æ•°æ®çš„ä¸å¯¹ç§°ç¨‹åº¦ã€‚
    ååº¦æ˜¯ä¸‰é˜¶ä¸­å¿ƒè·è®¡ç®—å‡ºæ¥çš„ã€‚
    ï¼ˆ1ï¼‰Skewness = 0 ï¼Œåˆ†å¸ƒå½¢æ€ä¸æ­£æ€åˆ†å¸ƒååº¦ç›¸åŒã€‚
    ï¼ˆ2ï¼‰Skewness > 0 ï¼Œæ­£åå·®æ•°å€¼è¾ƒå¤§ï¼Œä¸ºæ­£åæˆ–å³åã€‚é•¿å°¾å·´æ‹–åœ¨å³è¾¹ï¼Œæ•°æ®å³ç«¯æœ‰è¾ƒå¤šçš„æç«¯å€¼ã€‚
    ï¼ˆ3ï¼‰Skewness < 0 ï¼Œè´Ÿåå·®æ•°å€¼è¾ƒå¤§ï¼Œä¸ºè´Ÿåæˆ–å·¦åã€‚é•¿å°¾å·´æ‹–åœ¨å·¦è¾¹ï¼Œæ•°æ®å·¦ç«¯æœ‰è¾ƒå¤šçš„æç«¯å€¼ã€‚
    ï¼ˆ4ï¼‰æ•°å€¼çš„ç»å¯¹å€¼è¶Šå¤§ï¼Œè¡¨æ˜æ•°æ®åˆ†å¸ƒè¶Šä¸å¯¹ç§°ï¼Œåæ–œç¨‹åº¦å¤§ã€‚


  __df.kurt()  å³°åº¦__

    Definition:ååº¦æ˜¯æè¿°æŸå˜é‡æ‰€æœ‰å–å€¼åˆ†å¸ƒå½¢æ€é™¡ç¼“ç¨‹åº¦çš„ç»Ÿè®¡é‡ï¼Œç®€å•æ¥è¯´å°±æ˜¯æ•°æ®åˆ†å¸ƒé¡¶çš„å°–é”ç¨‹åº¦ã€‚
    å³°åº¦æ˜¯å››é˜¶æ ‡å‡†çŸ©è®¡ç®—å‡ºæ¥çš„ã€‚
    ï¼ˆ1ï¼‰Kurtosis=0 ä¸æ­£æ€åˆ†å¸ƒçš„é™¡ç¼“ç¨‹åº¦ç›¸åŒã€‚
    ï¼ˆ2ï¼‰Kurtosis>0 æ¯”æ­£æ€åˆ†å¸ƒçš„é«˜å³°æ›´åŠ é™¡å³­â€”â€”å°–é¡¶å³°
    ï¼ˆ3ï¼‰Kurtosis<0 æ¯”æ­£æ€åˆ†å¸ƒçš„é«˜å³°æ¥å¾—å¹³ç¼“â€”â€”å¹³é¡¶å³°

  ### pandas è®¡ç®—çŸ©é˜µå…³ç³»ç³»æ•°

  ä½¿ç”¨.corr() å¯ä»¥ç”¨äºè®¡ç®—çŸ©é˜µå…³ç³»ç³»æ•°ï¼Œå¯ä»¥ä½¿ç”¨å¾—åˆ°çš„å…³ç³»ç³»æ•°ç»˜åˆ¶çƒ­åŠ›å›¾
    
  __ä¸¾ä¾‹ï¼š__

    ç°åœ¨æˆ‘ä»¬æœ‰ä¸€äº›æ•°æ®ï¼Œæˆ‘ä»¬è¦è®¡ç®—è¿™äº›ç‰¹å¾ä¹‹é—´çš„å…³ç³»
    
    corrmat = train_data.drop('Id',axis=1).corr()   # train_data æ˜¯read_cav()è¯»å–è¿›æ¥çš„æ•°æ®
    corrmat

  __out__

    	            MSSubClass	LotFrontage	  LotArea	 OverallQual  OverallCond

    MSSubClass	  1.000000	  -0.386347	  -0.139781	  0.032628	  -0.059316	
    LotFrontage	  -0.386347 	1.000000	  0.426095	  0.251646	  -0.059213	
    LotArea	      -0.139781	  0.426095	  1.000000	  0.105806	  -0.005636	
    OverallQual	  0.032628	  0.251646  	0.105806	  1.000000	  -0.091932	
    OverallCond   -0.059316	  -0.059213	  -0.005636 	-0.091932	  1.000000	

  __ç»˜åˆ¶çƒ­åŠ›å›¾__

    fig,ax=plt.subplots(figsize=(20,16))
    sns.heatmap(corrmat,annot=True,fmt ='.1')
    plt.show()



  ## æ€»ç»“ï¼š
  
   å’Œ NumPy ä¸€æ ·ï¼ŒPandas æœ‰ä¸¤ä¸ªéå¸¸é‡è¦çš„æ•°æ®ç»“æ„ï¼šSeries å’Œ DataFrameã€‚ä½¿ç”¨ Pandas å¯ä»¥ç›´æ¥ä» csv æˆ– xlsx ç­‰æ–‡ä»¶ä¸­å¯¼å…¥æ•°æ®ï¼Œä»¥åŠæœ€ç»ˆè¾“å‡ºåˆ° excel è¡¨ä¸­ã€‚
   Pandas åŒ…ä¸ NumPy å·¥å…·åº“é…åˆä½¿ç”¨å¯ä»¥å‘æŒ¥å·¨å¤§çš„å¨åŠ›ï¼Œæ­£æ˜¯æœ‰äº† Pandas å·¥å…·ï¼ŒPython åšæ•°æ®æŒ–æ˜æ‰å…·æœ‰ä¼˜åŠ¿ã€‚
  
  
  
