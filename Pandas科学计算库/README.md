
# ğŸ“–pandasç”¨æ³•æ¢³ç†

## pandasä»‹ç»ï¼š
  åœ¨æ•°æ®åˆ†æå·¥ä½œä¸­ï¼ŒPandas çš„ä½¿ç”¨é¢‘ç‡æ˜¯å¾ˆé«˜çš„ï¼Œä¸€æ–¹é¢æ˜¯å› ä¸º Pandas æä¾›çš„åŸºç¡€æ•°æ®ç»“æ„ DataFrame ä¸ json çš„å¥‘åˆåº¦å¾ˆé«˜ï¼Œè½¬æ¢èµ·æ¥å°±å¾ˆæ–¹ä¾¿ã€‚
  å¦ä¸€æ–¹é¢ï¼Œå¦‚æœæˆ‘ä»¬æ—¥å¸¸çš„æ•°æ®æ¸…ç†å·¥ä½œä¸æ˜¯å¾ˆå¤æ‚çš„è¯ï¼Œä½ é€šå¸¸ç”¨å‡ å¥ Pandas ä»£ç å°±å¯ä»¥å¯¹æ•°æ®è¿›è¡Œè§„æ•´ã€‚

  Pandas å¯ä»¥è¯´æ˜¯åŸºäº NumPy æ„å»ºçš„å«æœ‰æ›´é«˜çº§æ•°æ®ç»“æ„å’Œåˆ†æèƒ½åŠ›çš„å·¥å…·åŒ…ã€‚åœ¨ NumPy ä¸­æ•°æ®ç»“æ„æ˜¯å›´ç»• ndarray å±•å¼€çš„ï¼Œé‚£ä¹ˆåœ¨ Pandas ä¸­çš„æ ¸å¿ƒæ•°æ®ç»“æ„æ˜¯ä»€ä¹ˆå‘¢ï¼Ÿ

  ä¸‹é¢ä¸»è¦ç»™ä½ è®²ä¸‹Series å’Œ DataFrame è¿™ä¸¤ä¸ªæ ¸å¿ƒæ•°æ®ç»“æ„ï¼Œä»–ä»¬åˆ†åˆ«ä»£è¡¨ç€ä¸€ç»´çš„åºåˆ—å’ŒäºŒç»´çš„è¡¨ç»“æ„ã€‚åŸºäºè¿™ä¸¤ç§æ•°æ®ç»“æ„ï¼ŒPandas å¯ä»¥å¯¹æ•°æ®è¿›è¡Œå¯¼å…¥ã€æ¸…æ´—ã€å¤„ç†ã€ç»Ÿè®¡å’Œè¾“å‡ºã€‚

## pandas.set_option é€‰é¡¹è®¾ç½®
  __å¯ä»¥è®¾ç½®pandasçš„å±æ€§ï¼Œæ¯”å¦‚æ‰“å°å‡ºæ¥æ•°æ®æ—¶æ˜¾ç¤ºå¤šå°‘åˆ—ï¼Œæ˜¾ç¤ºå¤šå®½ç­‰ç­‰ï¼Œå¯ä»¥ä¸€æ¬¡æ€§è®¾ç½®å¤šä¸ªæ ¼å¼å¦‚ä¸‹__
   
  è®¾ç½®pandasä¿ç•™å°æ•°ä½æ•°ä¸ºä¸‰ä½
  
    pd.set_option('display.float_format', lambda x: '%.3f' % x)
  
  é»˜è®¤æ˜¾ç¤ºåˆ—æ•°ï¼Œè¡Œæ•°,å½“è®¾ç½®ä¸ºNoneæ—¶ï¼Œè¡¨ç¤ºæ˜¾ç¤ºæ‰€æœ‰å†…å®¹
    
    pd.set_option('display.max_columns',5, 'display.max_rows', 100)
  
  è®¾ç½®pandasæ˜¾ç¤ºæ‰€æœ‰æ•°æ®å†…å®¹(ä¸éšè—æ•°æ®)ï¼š

  æ˜¾ç¤ºæ‰€æœ‰åˆ— (åˆ—ä¸­æœ‰çœç•¥çš„ä¸çœç•¥)

    pd.set_option('display.max_columns', None)
    
  __è§£å†³å¦‚ä¸‹é—®é¢˜ï¼š__

      11 12 13 ... 19 20
      21 22 23 ... 29 30
      31 32 33 ... 39 40
      41 42 43 ... 49 50

  æ˜¾ç¤ºæ‰€æœ‰è¡Œ (è¡Œä¸­æœ‰çœç•¥çš„ä¸çœç•¥)
  
    pd.set_option('display.max_rows', None)

  __è§£å†³å¦‚ä¸‹é—®é¢˜ï¼š__

      1 2 3
      4 5 6
      7 8 9
      ...
      100 101 102    
      
## æ•°æ®ç»“æ„Series å’Œ Dataframe

### Series
  __Series æ˜¯ä¸ªå®šé•¿çš„å­—å…¸åºåˆ—__ ã€‚è¯´æ˜¯å®šé•¿æ˜¯å› ä¸ºåœ¨å­˜å‚¨çš„æ—¶å€™ï¼Œç›¸å½“äºä¸¤ä¸ª ndarrayï¼Œè¿™ä¹Ÿæ˜¯å’Œå­—å…¸ç»“æ„æœ€å¤§çš„ä¸åŒã€‚å› ä¸ºåœ¨å­—å…¸çš„ç»“æ„é‡Œï¼Œå…ƒç´ çš„ä¸ªæ•°æ˜¯ä¸å›ºå®šçš„ã€‚
  
  __Series çš„ä¸¤ä¸ªåŸºæœ¬å±æ€§__ æœ‰ä¸¤ä¸ªåŸºæœ¬å±æ€§ï¼šindex å’Œ valuesã€‚åœ¨ Series ç»“æ„ä¸­ï¼Œindex é»˜è®¤æ˜¯ 0,1,2,â€¦â€¦é€’å¢çš„æ•´æ•°åºåˆ—ï¼Œå½“ç„¶æˆ‘ä»¬ä¹Ÿå¯ä»¥è‡ªå·±æ¥æŒ‡å®šç´¢å¼•ï¼Œæ¯”å¦‚ index=[â€˜aâ€™, â€˜bâ€™, â€˜câ€™, â€˜dâ€™]ã€‚
  
  __ä¾‹å­ï¼š__
  
    import pandas as pd
    from pandas import Series, DataFrame
    x1 = Series([1,2,3,4])
    x2 = Series(data=[1,2,3,4], index=['a', 'b', 'c', 'd'])
    print x1
    print x2

  
  __è¿è¡Œç»“æœï¼š__
  
    0    1
    1    2
    2    3
    3    4
    dtype: int64
    a    1
    b    2
    c    3
    d    4
    dtype: int64
    
è¿™ä¸ªä¾‹å­ä¸­ï¼Œx1 ä¸­çš„ index é‡‡ç”¨çš„æ˜¯é»˜è®¤å€¼ï¼Œx2 ä¸­ index è¿›è¡Œäº†æŒ‡å®šã€‚æˆ‘ä»¬ä¹Ÿå¯ä»¥é‡‡ç”¨å­—å…¸çš„æ–¹å¼æ¥åˆ›å»º Seriesï¼Œæ¯”å¦‚ï¼š

__ä¾‹å­ï¼š__

    d = {'a':1, 'b':2, 'c':3, 'd':4}
    x3 = Series(d)
    print x3 

__è¿è¡Œç»“æœï¼š__
  
    a    1
    b    2
    c    3
    d    4
    dtype: int64

### DataFrame ç±»å‹æ•°æ®ç»“æ„ç±»ä¼¼æ•°æ®åº“è¡¨ã€‚

  å®ƒåŒ…æ‹¬äº†è¡Œç´¢å¼•å’Œåˆ—ç´¢å¼•ï¼Œæˆ‘ä»¬å¯ä»¥å°† DataFrame çœ‹æˆæ˜¯ç”±ç›¸åŒç´¢å¼•çš„ Series ç»„æˆçš„å­—å…¸ç±»å‹ã€‚
  
  æˆ‘ä»¬è™šæ„ä¸€ä¸ªè€ƒè¯•çš„åœºæ™¯ï¼Œæƒ³è¦è¾“å‡ºå‡ ä½è‹±é›„çš„è€ƒè¯•æˆç»©ï¼š
    
    import pandas as pd
    from pandas import Series, DataFrame
    data = {'Chinese': [66, 95, 93, 90,80],'English': [65, 85, 92, 88, 90],'Math': [30, 98, 96, 77, 90]}
    df1= DataFrame(data)
    df2 = DataFrame(data, index=['ZhangFei', 'GuanYu', 'ZhaoYun', 'HuangZhong', 'DianWei'], columns=['English', 'Math', 'Chinese'])
    print df1
    print df2

  åœ¨åé¢çš„æ¡ˆä¾‹ä¸­ï¼Œæˆ‘ä¸€èˆ¬ä¼šç”¨ df, df1, df2 è¿™äº›ä½œä¸º DataFrame æ•°æ®ç±»å‹çš„å˜é‡åï¼Œæˆ‘ä»¬ä»¥ä¾‹å­ä¸­çš„ df2 ä¸ºä¾‹ï¼Œ
  åˆ—ç´¢å¼•æ˜¯ [â€˜Englishâ€™, â€˜Mathâ€™, â€˜Chineseâ€™]ï¼Œè¡Œç´¢å¼•æ˜¯ [â€˜ZhangFeiâ€™, â€˜GuanYuâ€™, â€˜ZhaoYunâ€™, â€˜HuangZhongâ€™, â€˜DianWeiâ€™]ï¼Œæ‰€ä»¥ df2 çš„è¾“å‡ºæ˜¯ï¼š
  
  
                  English  Math  Chinese
    ZhangFei         65    30       66
    GuanYu           85    98       95
    ZhaoYun          92    96       93
    HuangZhong       88    77       90
    DianWei          90    90       80

åœ¨äº†è§£äº† Series å’Œ DataFrame è¿™ä¸¤ä¸ªæ•°æ®ç»“æ„åï¼Œæˆ‘ä»¬å°±ä»æ•°æ®å¤„ç†çš„æµç¨‹è§’åº¦ï¼Œæ¥çœ‹ä¸‹ä»–ä»¬çš„ä½¿ç”¨æ–¹æ³•ã€‚

Pandas å…è®¸ç›´æ¥ä» xlsxï¼Œcsv ç­‰æ–‡ä»¶ä¸­å¯¼å…¥æ•°æ®ï¼Œä¹Ÿå¯ä»¥è¾“å‡ºåˆ° xlsx, csv ç­‰æ–‡ä»¶ï¼Œéå¸¸æ–¹ä¾¿ã€‚
  
    import pandas as pd
    from pandas import Series, DataFrame
    score = DataFrame(pd.read_excel('data.xlsx'))
    score.to_excel('data1.xlsx')
    print score
  
éœ€è¦è¯´æ˜çš„æ˜¯ï¼Œåœ¨è¿è¡Œçš„è¿‡ç¨‹å¯èƒ½ä¼šå­˜åœ¨ç¼ºå°‘ xlrd å’Œ openpyxl åŒ…çš„æƒ…å†µï¼Œåˆ°æ—¶å€™å¦‚æœç¼ºå°‘äº†ï¼Œå¯ä»¥åœ¨å‘½ä»¤è¡Œæ¨¡å¼ä¸‹ä½¿ç”¨â€œpip installâ€å‘½ä»¤æ¥è¿›è¡Œå®‰è£…ã€‚


### Dataframe å’Œ Series çš„å‘

___åœºæ™¯ï¼šåœ¨ä¸€æ®µdfæ•°æ®ä¸­æˆ‘ä»¬è¿›è¡Œå–å€¼__

__æ•°æ®ï¼š__
  
    train_data.head()

__outï¼š__

      Survived	Pclass	Sex	Age	Fare	Embarked	Title	Isalone
    0 	0	      3	      1	  1	  0   	2	        2	    0
    1	  1	      1	      0	  2	  0	    0	        3	    0
    2	  1	      3	      0	  1	  0   	2	        1	    1
    3	  1	      1	      0	  2	  0	    2	        3	    0
    4	  0	      3	      1	  2	  0	    2	        2	    1


__åŒæ‹¬å·å’Œå•æ‹¬å·ä¹‹é—´çš„åŒºåˆ«ï¼š__

__åŒæ‹¬å·å–å‡ºçš„ Survived æ˜¯ DataFrame æ ¼å¼__

    type(train_data[['Survived']].head())

    pandas.core.frame.DataFrame

__å•æ‹¬å·å–å‡ºçš„ Survived æ˜¯ Series æ ¼å¼__

    type(train_data['Survived'].head())
    pandas.core.series.Series

å–å‡ºæ¥ä¸º Series æ ¼å¼ï¼Œä½†æ˜¯ä½ æ²¡æœ‰å‘è§‰ï¼Œæ­¤åå¦‚æœæƒ³èµ‹å€¼ä¸€ä¸ªæ–°çš„åˆ—ï¼Œé‚£ä¹ˆæ— æ³•æˆåŠŸï¼Œå› ä¸ºSeriesä¸­åªèƒ½æœ‰ä¸€åˆ—ã€‚



### pandas æ•°æ®ç±»å‹

Pandas __dtype__ æ˜ å°„ï¼š

<div align=center><img width="700" height="430" src="https://raw.githubusercontent.com/OneStepAndTwoSteps/data_mining_analysis/master/static/pandas/3.png"/></div>


### å°† object ç±»å‹è½¬ä¸º category åˆ†ç±»ç±»å‹





### æ•°æ®æ¸…æ´—
  æ•°æ®æ¸…æ´—æ˜¯æ•°æ®å‡†å¤‡è¿‡ç¨‹ä¸­å¿…ä¸å¯å°‘çš„ç¯èŠ‚ï¼ŒPandas ä¹Ÿä¸ºæˆ‘ä»¬æä¾›äº†æ•°æ®æ¸…æ´—çš„å·¥å…·ï¼Œåœ¨åé¢æ•°æ®æ¸…æ´—çš„ç« èŠ‚ä¸­ä¼šç»™ä½ åšè¯¦ç»†çš„ä»‹ç»ï¼Œè¿™é‡Œç®€å•ä»‹ç»ä¸‹ Pandas åœ¨æ•°æ®æ¸…æ´—ä¸­çš„ä½¿ç”¨æ–¹æ³•ã€‚
  
  è¿˜æ˜¯ä»¥ä¸Šé¢è¿™äº›è‹±é›„äººç‰©çš„æ•°æ®ä¸ºä¾‹ã€‚
  
    data = {'Chinese': [66, 95, 93, 90,80],'English': [65, 85, 92, 88, 90],'Math': [30, 98, 96, 77, 90]}
    df2 = DataFrame(data, index=['ZhangFei', 'GuanYu', 'ZhaoYun', 'HuangZhong', 'DianWei'], columns=['English', 'Math', 'Chinese'])

  åœ¨æ•°æ®æ¸…æ´—è¿‡ç¨‹ä¸­ï¼Œä¸€èˆ¬éƒ½ä¼šé‡åˆ°ä»¥ä¸‹è¿™å‡ ç§æƒ…å†µï¼Œä¸‹é¢æˆ‘æ¥ç®€å•ä»‹ç»ä¸€ä¸‹ã€‚
  
  __1. åˆ é™¤ DataFrame ä¸­çš„ä¸å¿…è¦çš„åˆ—æˆ–è¡Œï¼š__
  
  Pandas æä¾›äº†ä¸€ä¸ªä¾¿æ·çš„æ–¹æ³• drop() å‡½æ•°æ¥åˆ é™¤æˆ‘ä»¬ä¸æƒ³è¦çš„åˆ—æˆ–è¡Œã€‚æ¯”å¦‚æˆ‘ä»¬æƒ³æŠŠâ€œè¯­æ–‡â€è¿™åˆ—åˆ æ‰ã€‚
    
    df2 = df2.drop(columns=['Chinese'])

  æƒ³æŠŠâ€œå¼ é£â€è¿™è¡Œåˆ æ‰ã€‚
  
    df2 = df2.drop(index=['ZhangFei'])
  
  åˆªé™¤ä¸éœ€è¦çš„åˆ—åä¹Ÿå¯ä»¥ç”¨delete()ï¼Œåˆ é™¤train_data.columnsçš„ç¬¬ä¸€åˆ—ï¼Œæ³¨æ„deleteä¸èƒ½å¯¹dfæ•°æ®ç±»å‹ä½¿ç”¨ã€‚

    coeff_df = pd.DataFrame(train_data.columns.delete(0))


  __2. é‡å‘½ååˆ—å columnsï¼Œè®©åˆ—è¡¨åæ›´å®¹æ˜“è¯†åˆ«ï¼š__
  
  å¦‚æœä½ æƒ³å¯¹ DataFrame ä¸­çš„ columns è¿›è¡Œé‡å‘½åï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨ rename(columns=new_names, inplace=True) å‡½æ•°ï¼Œæ¯”å¦‚æˆ‘æŠŠåˆ—å Chinese æ”¹æˆ YuWenï¼ŒEnglish æ”¹æˆ YingYuã€‚
  
    # inplaceï¼šåˆ·é€‰è¿‡ç¼ºå¤±å€¼å¾—æ–°æ•°æ®æ˜¯å­˜ä¸ºå‰¯æœ¬è¿˜æ˜¯ç›´æ¥åœ¨åŸæ•°æ®ä¸Šè¿›è¡Œä¿®æ”¹ã€‚
    df2.rename(columns={'Chinese': 'YuWen', 'English': 'Yingyu'}, inplace = True)

  __3. å»é‡å¤çš„å€¼ï¼š__
    æ•°æ®é‡‡é›†å¯èƒ½å­˜åœ¨é‡å¤çš„è¡Œï¼Œè¿™æ—¶åªè¦ä½¿ç”¨ drop_duplicates() å°±ä¼šè‡ªåŠ¨æŠŠé‡å¤çš„è¡Œå»æ‰ã€‚
  
      df = df.drop_duplicates() # å»é™¤é‡å¤è¡Œ

  __4. æ ¼å¼é—®é¢˜ï¼š__
    è¿™æ˜¯ä¸ªæ¯”è¾ƒå¸¸ç”¨çš„æ“ä½œï¼Œå› ä¸ºå¾ˆå¤šæ—¶å€™æ•°æ®æ ¼å¼ä¸è§„èŒƒï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ astype å‡½æ•°æ¥è§„èŒƒæ•°æ®æ ¼å¼ï¼Œæ¯”å¦‚æˆ‘ä»¬æŠŠ Chinese å­—æ®µçš„å€¼æ”¹æˆ str ç±»å‹ï¼Œæˆ–è€… int64 å¯ä»¥è¿™ä¹ˆå†™ï¼š
  
      df2['Chinese'].astype('str') 
      df2['Chinese'].astype(np.int64) 

  
### æ•°æ®é—´çš„ç©ºæ ¼

  æœ‰æ—¶å€™æˆ‘ä»¬å…ˆæŠŠæ ¼å¼è½¬æˆäº† str ç±»å‹ï¼Œæ˜¯ä¸ºäº†æ–¹ä¾¿å¯¹æ•°æ®è¿›è¡Œæ“ä½œï¼Œè¿™æ—¶æƒ³è¦åˆ é™¤æ•°æ®é—´çš„ç©ºæ ¼ï¼Œæˆ‘ä»¬å°±å¯ä»¥ä½¿ç”¨ strip å‡½æ•°ï¼š
  
    # åˆ é™¤å·¦å³ä¸¤è¾¹ç©ºæ ¼
    df2['Chinese']=df2['Chinese'].map(str.strip)
    # åˆ é™¤å·¦è¾¹ç©ºæ ¼
    df2['Chinese']=df2['Chinese'].map(str.lstrip)
    # åˆ é™¤å³è¾¹ç©ºæ ¼
    df2['Chinese']=df2['Chinese'].map(str.rstrip)

  å¦‚æœæ•°æ®é‡Œæœ‰æŸä¸ªç‰¹æ®Šçš„ç¬¦å·ï¼Œæˆ‘ä»¬æƒ³è¦åˆ é™¤æ€ä¹ˆåŠï¼ŸåŒæ ·å¯ä»¥ä½¿ç”¨ strip å‡½æ•°ï¼Œæ¯”å¦‚ Chinese å­—æ®µé‡Œæœ‰ç¾å…ƒç¬¦å·ï¼Œæˆ‘ä»¬æƒ³æŠŠè¿™ä¸ªåˆ æ‰ï¼Œå¯ä»¥è¿™ä¹ˆå†™ï¼š

    df2['Chinese']=df2['Chinese'].str.strip('$')


__å¤§å°å†™è½¬æ¢ï¼š__
  
  å¤§å°å†™æ˜¯ä¸ªæ¯”è¾ƒå¸¸è§çš„æ“ä½œï¼Œæ¯”å¦‚äººåã€åŸå¸‚åç­‰çš„ç»Ÿä¸€éƒ½å¯èƒ½ç”¨åˆ°å¤§å°å†™çš„è½¬æ¢ï¼Œåœ¨ Python é‡Œç›´æ¥ä½¿ç”¨ upper(), lower(), title() å‡½æ•°ï¼Œæ–¹æ³•å¦‚ä¸‹ï¼š
  
    # å…¨éƒ¨å¤§å†™
    df2.columns = df2.columns.str.upper()
    # å…¨éƒ¨å°å†™
    df2.columns = df2.columns.str.lower()
    # é¦–å­—æ¯å¤§å†™
    df2.columns = df2.columns.str.title()

  
__æŸ¥æ‰¾ç©ºå€¼ï¼š__

  æ•°æ®é‡å¤§çš„æƒ…å†µä¸‹ï¼Œæœ‰äº›å­—æ®µå­˜åœ¨ç©ºå€¼ NaN çš„å¯èƒ½ï¼Œè¿™æ—¶å°±éœ€è¦ä½¿ç”¨ Pandas ä¸­çš„ __isnull__ å‡½æ•°è¿›è¡ŒæŸ¥æ‰¾ã€‚æ¯”å¦‚ï¼Œæˆ‘ä»¬è¾“å…¥ä¸€ä¸ªæ•°æ®è¡¨å¦‚ä¸‹ï¼š
    
    å§“å     è¯­æ–‡     è‹±è¯­     æ•°å­¦
    
    å¼ é£     66       65        
    
    å…³ç¾½     95       85       98   
  
    èµµäº‘     95       92       96   
    
    é»„å¿      90       88       77   
  
    å…¸éŸ¦     80       90       90   
  
  
  
  å¦‚æœæˆ‘ä»¬æƒ³çœ‹ä¸‹å“ªä¸ªåœ°æ–¹å­˜åœ¨ç©ºå€¼ NaNï¼Œå¯ä»¥é’ˆå¯¹æ•°æ®è¡¨ dfè¿›è¡Œ __df.isnull()__ :ç»“æœå¦‚ä¸‹

        å§“å      è¯­æ–‡     è‹±è¯­     æ•°å­¦
     0  False    False    False    True   
     1  False    False    False    False   
     2  False    False    False    False   
     3  False    False    False    False   
     4  False    False    False    False   

  
  å¦‚æœæˆ‘æƒ³çŸ¥é“å“ªåˆ—å­˜åœ¨ç©ºå€¼ï¼Œå¯ä»¥ä½¿ç”¨ __df.isnull().any()__ ï¼Œç»“æœå¦‚ä¸‹ï¼š
  
    å§“å     False
    è¯­æ–‡     False
    è‹±è¯­     False
    æ•°å­¦     True
  
  __ç›´æ¥æŸ¥çœ‹é‚£ä¸ªåˆ—å­˜åœ¨ç©ºå€¼ï¼š__

    train.isnull().any()[train.isnull().any().values==True]

  outï¼š

    overview    True
    runtime     True
    tagline     True
    dtype: bool

  
  __ä½¿ç”¨ apply å‡½æ•°å¯¹æ•°æ®è¿›è¡Œæ¸…æ´—ï¼š__
  
    apply å‡½æ•°æ˜¯ Pandas ä¸­è‡ªç”±åº¦éå¸¸é«˜çš„å‡½æ•°ï¼Œä½¿ç”¨é¢‘ç‡ä¹Ÿéå¸¸é«˜ã€‚
    æ¯”å¦‚æˆ‘ä»¬æƒ³å¯¹ name åˆ—çš„æ•°å€¼éƒ½è¿›è¡Œå¤§å†™è½¬åŒ–å¯ä»¥ç”¨ï¼š
  
      df['name'] = df['name'].apply(str.upper)
      
    æˆ‘ä»¬ä¹Ÿå¯ä»¥å®šä¹‰ä¸ªå‡½æ•°ï¼Œåœ¨ apply ä¸­è¿›è¡Œä½¿ç”¨ã€‚æ¯”å¦‚å®šä¹‰ double_df å‡½æ•°æ˜¯å°†åŸæ¥çš„æ•°å€¼ *2 è¿›è¡Œè¿”å›ã€‚ç„¶åå¯¹ df1 ä¸­çš„â€œè¯­æ–‡â€åˆ—çš„æ•°å€¼è¿›è¡Œ *2 å¤„ç†ï¼Œå¯ä»¥å†™æˆï¼š
  
      def double_df(x):
           return 2*x
      df1[u'è¯­æ–‡'] = df1[u'è¯­æ–‡'].apply(double_df)

    æˆ‘ä»¬ä¹Ÿå¯ä»¥å®šä¹‰æ›´å¤æ‚çš„å‡½æ•°ï¼Œæ¯”å¦‚å¯¹äº DataFrameï¼Œæˆ‘ä»¬æ–°å¢ä¸¤åˆ—ï¼Œå…¶ä¸­â€™new1â€™åˆ—æ˜¯â€œè¯­æ–‡â€å’Œâ€œè‹±è¯­â€æˆç»©ä¹‹å’Œçš„ m å€ï¼Œ'new2â€™åˆ—æ˜¯â€œè¯­æ–‡â€å’Œâ€œè‹±è¯­â€æˆç»©ä¹‹å’Œçš„ n å€ï¼Œæˆ‘ä»¬å¯ä»¥è¿™æ ·å†™ï¼š
      
        def plus(df,n,m):
          df['new1'] = (df[u'è¯­æ–‡']+df[u'è‹±è¯­']) * m
          df['new2'] = (df[u'è¯­æ–‡']+df[u'è‹±è¯­']) * n
          return df
        df1 = df1.apply(plus,axis=1,args=(2,3,))

    å…¶ä¸­ axis=1 ä»£è¡¨æŒ‰ç…§åˆ—ä¸ºè½´è¿›è¡Œæ“ä½œï¼Œaxis=0 ä»£è¡¨æŒ‰ç…§è¡Œä¸ºè½´è¿›è¡Œæ“ä½œï¼Œargs æ˜¯ä¼ é€’çš„ä¸¤ä¸ªå‚æ•°ï¼Œå³ n=2, m=3ï¼Œåœ¨ plus å‡½æ•°ä¸­ä½¿ç”¨åˆ°äº† n å’Œ mï¼Œä»è€Œç”Ÿæˆæ–°çš„ dfã€‚
  
  __ä½¿ç”¨ apply å‡½æ•°å¯¹æ•°æ®è¿›è¡Œæ¸…æ´— (è¿›é˜¶) ï¼š__
    
    # å°† train['production_companies'] ä¸­çš„æ•°æ®ä½œä¸º x ä¼ ç»™applyå‡½æ•°ï¼Œåœ¨applyä¸­åšå¤„ç†
    # (å–å¾—çš„ production_companies ç‰¹å¾ä¸­çš„æ‰€æœ‰æ•°æ® [è¯¥æ•°æ®æ˜¯ä¸€ä¸ªå­—å…¸] ç„¶ååšif elseåˆ¤æ–­)
    
    train['production_companies'].apply(lambda x: [i['name'] for i in x] if x != {} else []).values


__è‡ªå®šä¹‰å‡½æ•°apply__
 
      def search_hundredth(train_content):
          hundredth=train_content.loc[99]
          return hundredth

      search_func=train_content.apply(search_hundredth)
      print(search_func)

      1. ä¸åŒäº transform åªå…è®¸åœ¨ Series ä¸Šè¿›è¡Œä¸€æ¬¡è½¬æ¢ï¼Œ applyå¯¹æ•´ä¸ªDataFrame ä½œç”¨

      2.applyéšå¼åœ°å°†group ä¸Šæ‰€æœ‰çš„åˆ—ä½œä¸ºè‡ªå®šä¹‰å‡½æ•°

__è‡ªå®šä¹‰å‡½æ•° transfrom__

  apply()é‡Œé¢å¯ä»¥è·Ÿè‡ªå®šä¹‰çš„å‡½æ•°ï¼ŒåŒ…æ‹¬ç®€å•çš„æ±‚å’Œå‡½æ•°ä»¥åŠå¤æ‚çš„ç‰¹å¾é—´çš„å·®å€¼å‡½æ•°ç­‰ï¼ˆæ³¨ï¼šapplyä¸èƒ½ç›´æ¥ä½¿ç”¨agg()æ–¹æ³• / transform()ä¸­çš„pythonå†…ç½®å‡½æ•°ï¼Œä¾‹å¦‚sumã€maxã€minã€'countâ€˜ç­‰æ–¹æ³•ï¼‰

  transform() é‡Œé¢ä¸èƒ½è·Ÿè‡ªå®šä¹‰çš„ç‰¹å¾äº¤äº’å‡½æ•°ï¼Œå› ä¸ºtransformæ˜¯çœŸé’ˆå¯¹æ¯ä¸€å…ƒç´ ï¼ˆå³æ¯ä¸€åˆ—ç‰¹å¾æ“ä½œï¼‰è¿›è¡Œè®¡ç®—ï¼Œä¹Ÿå°±æ˜¯è¯´åœ¨ä½¿ç”¨ transform() æ–¹æ³•æ—¶ï¼Œéœ€è¦è®°å¾—ä¸‰ç‚¹ï¼š

  1ã€__å®ƒåªèƒ½å¯¹æ¯ä¸€åˆ—è¿›è¡Œè®¡ç®—__ï¼Œæ‰€ä»¥åœ¨groupby()ä¹‹åï¼Œ.transform()ä¹‹å‰æ˜¯è¦æŒ‡å®šè¦æ“ä½œçš„åˆ—ï¼Œè¿™ç‚¹ä¹Ÿä¸applyæœ‰å¾ˆå¤§çš„ä¸åŒã€‚

  2ã€ç”±äºæ˜¯åªèƒ½å¯¹æ¯ä¸€åˆ—è®¡ç®—ï¼Œæ‰€ä»¥æ–¹æ³•çš„é€šç”¨æ€§ç›¸æ¯”apply()å°±å±€é™äº†å¾ˆå¤šï¼Œä¾‹å¦‚åªèƒ½æ±‚åˆ—çš„æœ€å¤§/æœ€å°/å‡å€¼/æ–¹å·®/åˆ†ç®±ç­‰æ“ä½œ

  3ã€transformè¿˜æœ‰ä»€ä¹ˆç”¨å‘¢?æœ€ç®€å•çš„æƒ…å†µæ˜¯è¯•å›¾å°†å‡½æ•°çš„ç»“æœåˆ†é…å›åŸå§‹çš„dataframeã€‚ä¹Ÿå°±æ˜¯è¯´è¿”å›çš„shapeæ˜¯ (len(df)ï¼Œ1)ã€‚æ³¨ï¼šå¦‚æœä¸groupby()æ–¹æ³•è”åˆä½¿ç”¨ï¼Œéœ€è¦å¯¹å€¼è¿›è¡Œå»é‡ã€‚


__transform å’Œ applyçš„ç›¸åŒä¹‹å¤„ï¼š__

  éƒ½èƒ½é’ˆå¯¹dataframeå®Œæˆç‰¹å¾çš„è®¡ç®—ï¼Œå¹¶ä¸”å¸¸å¸¸ä¸groupby()æ–¹æ³•ä¸€èµ·ä½¿ç”¨ã€‚



  ### æ•°æ®ç»Ÿè®¡
  
    åœ¨æ•°æ®æ¸…æ´—åï¼Œæˆ‘ä»¬å°±è¦å¯¹æ•°æ®è¿›è¡Œç»Ÿè®¡äº†ã€‚Pandas å’Œ NumPy ä¸€æ ·ï¼Œéƒ½æœ‰å¸¸ç”¨çš„ç»Ÿè®¡å‡½æ•°ï¼Œå¦‚æœé‡åˆ°ç©ºå€¼ NaNï¼Œä¼šè‡ªåŠ¨æ’é™¤ã€‚
    å¸¸ç”¨çš„ç»Ÿè®¡å‡½æ•°åŒ…æ‹¬ï¼š
    ä»¥ä¸‹å‡½æ•°å¯ä»¥æŒ‡å®šè®¡ç®—çš„axisä¸ºè¡Œè¿˜æ˜¯åˆ—ï¼Œé»˜è®¤ä¸ºè¡Œ(å°±æ˜¯æŸä¸€åˆ—ä¸­çš„æ¯ä¸€è¡Œç‰¹å¾) axis=0ã€‚æ³¨æ„å¦‚æœè®¡ç®—æ‰€åœ¨æŸä¸€åˆ—/è¡Œä¸­å­˜åœ¨å­—ç¬¦ï¼Œåˆ™è¯¥åˆ—/è¡Œå°†ä¸è¿›è¡Œè®¡ç®—
 
      count()     ç»Ÿè®¡ä¸ªæ•°ï¼Œç©ºå€¼NaNä¸è®¡ç®—
      describe()  ä¸€æ¬¡æ€§è¾“å‡ºå¤šä¸ªç»Ÿè®¡æŒ‡æ ‡ï¼ŒåŒ…æ‹¬ï¼šcount,mean,std,min,max ç­‰
      min()       æœ€å°å€¼
      max()       æœ€å¤§å€¼
      sum()       æ€»å’Œ
      mean()      å¹³å‡å€¼
      median()    ä¸­ä½æ•°
      var()       æ–¹å·®
      std()       æ ‡å‡†å·®
      argmin()    ç»Ÿè®¡æœ€å°å€¼çš„ç´¢å¼•ä½ç½®
      argmax()    ç»Ÿè®¡æœ€å¤§å€¼çš„ç´¢å¼•ä½ç½®
      idxmin()    ç»Ÿè®¡æœ€å°å€¼çš„ç´¢å¼•å€¼
      idxmax()    ç»Ÿè®¡æœ€å¤§å€¼çš„ç´¢å¼•å€¼
      
      
   è¡¨æ ¼ä¸­æœ‰ä¸€ä¸ª describe() å‡½æ•°ï¼Œç»Ÿè®¡å‡½æ•°åƒåƒä¸‡ï¼Œdescribe() å‡½æ•°æœ€ç®€ä¾¿ã€‚å®ƒæ˜¯ä¸ªç»Ÿè®¡å¤§ç¤¼åŒ…ï¼Œå¯ä»¥å¿«é€Ÿè®©æˆ‘ä»¬å¯¹æ•°æ®æœ‰ä¸ªå…¨é¢çš„äº†è§£ã€‚ä¸‹é¢æˆ‘ç›´æ¥ä½¿ç”¨ df1.describe() è¾“å‡ºç»“æœä¸ºï¼š
      
   åˆ†ææ³°å¦å°¼å…‹æ•°æ®ä¸ºä¾‹ï¼š

      train_df.describe() # é»˜è®¤åªè®¡ç®—æ•°å€¼ç±»å‹

      out:

            PassengerId	  Survived	 Pclass	       Age	       SibSp	     Parch	    Fare
      count	891.000000	 891.000000	891.000000	714.000000	891.000000	891.000000	891.000000
      mean	446.000000	 0.383838	  2.308642	  29.699118	  0.523008  	0.381594	  32.204208
      std	  257.353842	  0.486592	0.836071  	14.526497	  1.102743	  0.806057	  49.693429
      min	  1.000000	    0.000000	1.000000  	0.420000	  0.000000	  0.000000	  0.000000
      25%	  223.500000	  0.000000	2.000000	  20.125000	  0.000000	  0.000000	  7.910400
      50%	  446.000000	  0.000000	3.000000	  28.000000	  0.000000	  0.000000	  14.454200
      75%	  668.500000	  1.000000	3.000000	  38.000000	  1.000000	  0.000000	  31.000000
      max	  891.000000	  1.000000	3.000000	  80.000000	  8.000000	  6.000000	  512.329200

      train_df.describe(include=['O']) # åªè®¡ç®—ç±»å‹ä¸ºstrçš„æ•°æ®
      
      out:
      
            Name	                           Sex	Ticket	Cabin	       Embarked
      count	  891         	                 891	891	     204	          889
      unique	891	                           2	  681	     147	          3
      top	Panula, Master. Juha Niilo	       male	1601	C23 C25 C27	      S
      freq    1                              577	7	         4	          644


   __è¿è¡Œç»“æœ:__  
   
  ![Image text](https://raw.githubusercontent.com/OneStepAndTwoSteps/data_mining_analysis/master/static/describe.png)
        
   __æ•°æ®è¡¨åˆå¹¶__
    
   æœ‰æ—¶å€™æˆ‘ä»¬éœ€è¦å°†å¤šä¸ªæ¸ é“æºçš„å¤šä¸ªæ•°æ®è¡¨è¿›è¡Œåˆå¹¶ï¼Œä¸€ä¸ª DataFrame ç›¸å½“äºä¸€ä¸ªæ•°æ®åº“çš„æ•°æ®è¡¨ï¼Œé‚£ä¹ˆå¤šä¸ª DataFrame æ•°æ®è¡¨çš„åˆå¹¶å°±ç›¸å½“äºå¤šä¸ªæ•°æ®åº“çš„è¡¨åˆå¹¶ã€‚
    
   æ¯”å¦‚æˆ‘è¦åˆ›å»ºä¸¤ä¸ª DataFrameï¼š
    
      df1 = DataFrame({'name':['ZhangFei', 'GuanYu', 'a', 'b', 'c'], 'data1':range(5)})
      df2 = DataFrame({'name':['ZhangFei', 'GuanYu', 'A', 'B', 'C'], 'data2':range(5)})

   __1. åŸºäºæŒ‡å®šåˆ—è¿›è¡Œè¿æ¥__
      
   æ¯”å¦‚æˆ‘ä»¬å¯ä»¥åŸºäº name è¿™åˆ—è¿›è¡Œè¿æ¥ã€‚
    
        df3 = pd.merge(df1, df2, on='name')

   __è¿è¡Œç»“æœ:__ 
   
   ![Image text](https://raw.githubusercontent.com/OneStepAndTwoSteps/data_mining_analysis/master/static/1.png)
    
    
   __2. inner å†…è¿æ¥__
        
   inner å†…é“¾æ¥æ˜¯ merge åˆå¹¶çš„é»˜è®¤æƒ…å†µï¼Œinner å†…è¿æ¥å…¶å®ä¹Ÿå°±æ˜¯é”®çš„äº¤é›†ï¼Œåœ¨è¿™é‡Œ df1, df2 ç›¸åŒçš„é”®æ˜¯ nameï¼Œæ‰€ä»¥æ˜¯åŸºäº name å­—æ®µåšçš„è¿æ¥ï¼š
     
        df3 = pd.merge(df1, df2, how='inner')
   __è¿è¡Œç»“æœ:__ 
   
   ![Image text](https://raw.githubusercontent.com/OneStepAndTwoSteps/data_mining_analysis/master/static/2-1.png)
    
   __3. left å·¦è¿æ¥__
    
   å·¦è¿æ¥æ˜¯ä»¥ç¬¬ä¸€ä¸ª DataFrame ä¸ºä¸»è¿›è¡Œçš„è¿æ¥ï¼Œç¬¬äºŒä¸ª DataFrame ä½œä¸ºè¡¥å……ã€‚
        
          df3 = pd.merge(df1, df2, how='left')
   __è¿è¡Œç»“æœ:__
   
  ![Image text](https://raw.githubusercontent.com/OneStepAndTwoSteps/data_mining_analysis/master/static/3.png)

   __4. right å³è¿æ¥__
        
   å³è¿æ¥æ˜¯ä»¥ç¬¬äºŒä¸ª DataFrame ä¸ºä¸»è¿›è¡Œçš„è¿æ¥ï¼Œç¬¬ä¸€ä¸ª DataFrame ä½œä¸ºè¡¥å……ã€‚
      
        df3 = pd.merge(df1, df2, how='right')
   __è¿è¡Œç»“æœ:__
   
  ![Image text](https://raw.githubusercontent.com/OneStepAndTwoSteps/data_mining_analysis/master/static/4.png)

   __5. outer å¤–è¿æ¥__

   å¤–è¿æ¥ç›¸å½“äºæ±‚ä¸¤ä¸ª DataFrame çš„å¹¶é›†ã€‚
        
        df3 = pd.merge(df1, df2, how='outer')
   __è¿è¡Œç»“æœ:__
   
  ![Image text](https://raw.githubusercontent.com/OneStepAndTwoSteps/data_mining_analysis/master/static/5.png)
  
 ### å¦‚ä½•ç”¨ SQL æ–¹å¼æ‰“å¼€ Pandas
    
 Pandas çš„ DataFrame æ•°æ®ç±»å‹å¯ä»¥è®©æˆ‘ä»¬åƒå¤„ç†æ•°æ®è¡¨ä¸€æ ·è¿›è¡Œæ“ä½œï¼Œæ¯”å¦‚æ•°æ®è¡¨çš„å¢åˆ æ”¹æŸ¥ï¼Œéƒ½å¯ä»¥ç”¨ Pandas å·¥å…·æ¥å®Œæˆã€‚
 ä¸è¿‡ä¹Ÿä¼šæœ‰å¾ˆå¤šäººè®°ä¸ä½è¿™äº› Pandas çš„å‘½ä»¤ï¼Œç›¸æ¯”ä¹‹ä¸‹è¿˜æ˜¯ç”¨ SQL è¯­å¥æ›´ç†Ÿç»ƒï¼Œç”¨ SQL å¯¹æ•°æ®è¡¨è¿›è¡Œæ“ä½œæ˜¯æœ€æ–¹ä¾¿çš„ï¼Œå®ƒçš„è¯­å¥æè¿°å½¢å¼æ›´æ¥è¿‘æˆ‘ä»¬çš„è‡ªç„¶è¯­è¨€ã€‚
    
 äº‹å®ä¸Šï¼Œåœ¨ Python é‡Œå¯ä»¥ç›´æ¥ä½¿ç”¨ SQL è¯­å¥æ¥æ“ä½œ Pandasã€‚
    
 __è¿™é‡Œç»™ä½ ä»‹ç»ä¸ªå·¥å…·ï¼špandasqlã€‚__
    
 pandasql ä¸­çš„ä¸»è¦å‡½æ•°æ˜¯ sqldfï¼Œå®ƒæ¥æ”¶ä¸¤ä¸ªå‚æ•°ï¼šä¸€ä¸ª SQL æŸ¥è¯¢è¯­å¥ï¼Œè¿˜æœ‰ä¸€ç»„ç¯å¢ƒå˜é‡ globals() æˆ– locals()ã€‚è¿™æ ·æˆ‘ä»¬å°±å¯ä»¥åœ¨ Python é‡Œï¼Œç›´æ¥ç”¨ SQL è¯­å¥ä¸­å¯¹ DataFrame è¿›è¡Œæ“ä½œï¼Œä¸¾ä¸ªä¾‹å­ï¼šimport pandas as pd
     
  __ä¾‹å­ï¼š__
    
      from pandas import DataFrame
      from pandasql import sqldf, load_meat, load_births
      df1 = DataFrame({'name':['ZhangFei', 'GuanYu', 'a', 'b', 'c'], 'data1':range(5)})
      pysqldf = lambda sql: sqldf(sql, globals())
      sql = "select * from df1 where name ='ZhangFei'"
      print pysqldf(sql)

    
  __è¿è¡Œç»“æœï¼š__
  
      data1      name
      0      0  ZhangFei

  ä¸Šé¢è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬æ˜¯å¯¹â€œname='ZhangFeiâ€â€œçš„è¡Œè¿›è¡Œäº†è¾“å‡ºã€‚å½“ç„¶ä½ ä¼šçœ‹åˆ°æˆ‘ä»¬ç”¨åˆ°äº† lambdaï¼Œlambda åœ¨ python ä¸­ç®—æ˜¯ä½¿ç”¨é¢‘ç‡å¾ˆé«˜çš„ï¼Œé‚£ lambda æ˜¯ç”¨æ¥åšä»€ä¹ˆçš„å‘¢ï¼Ÿ
  å®ƒå®é™…ä¸Šæ˜¯ç”¨æ¥å®šä¹‰ä¸€ä¸ªåŒ¿åå‡½æ•°çš„ï¼Œå…·ä½“çš„ä½¿ç”¨å½¢å¼ä¸ºï¼š
  
      lambda argument_list: expression

  
  
  è¿™é‡Œ argument_list æ˜¯å‚æ•°åˆ—è¡¨ï¼Œexpression æ˜¯å…³äºå‚æ•°çš„è¡¨è¾¾å¼ï¼Œä¼šæ ¹æ® expression è¡¨è¾¾å¼è®¡ç®—ç»“æœè¿›è¡Œè¾“å‡ºè¿”å›ã€‚
  
  åœ¨ä¸Šé¢çš„ä»£ç ä¸­ï¼Œæˆ‘ä»¬å®šä¹‰äº†ï¼š
  
    pysqldf = lambda sql: sqldf(sql, globals())

  åœ¨è¿™ä¸ªä¾‹å­é‡Œï¼Œè¾“å…¥çš„å‚æ•°æ˜¯ sqlï¼Œè¿”å›çš„ç»“æœæ˜¯ sqldf å¯¹ sql çš„è¿è¡Œç»“æœï¼Œå½“ç„¶ sqldf ä¸­ä¹Ÿè¾“å…¥äº† globals å…¨å±€å‚æ•°ï¼Œå› ä¸ºåœ¨ sql ä¸­æœ‰å¯¹å…¨å±€å‚æ•° df1 çš„ä½¿ç”¨ã€‚
  
  ### è¯»å–æ–‡ä»¶é‡Œçš„å†…å®¹
  ä»¥csvçš„æ ¼å¼è¯»å–æ–‡ä»¶é‡Œçš„å†…å®¹
    
    train_content=pd.read_csv("train.csv")
  
  ä»¥xlsçš„æ ¼å¼è¯»å–æ–‡ä»¶é‡Œçš„å†…å®¹ (excelæ–‡ä»¶è¯»å–æ–¹å¼)
    
    train_content=pd.read_excel("train.xls")
    
  æ˜¾ç¤ºpd_contentçš„å‰é¢ä¸‰è¡Œ(ä¸åŒ…æ‹¬åˆ—åå­—)  
     
     print(train_content.head(3)
  
  pivot_tableå‡½æ•°
    
  pivot_tableæœ‰å››ä¸ªæœ€é‡è¦çš„å‚æ•°indexã€valuesã€columnsã€aggfunc

  index     indexä»£è¡¨ç´¢å¼•ï¼Œæ¯ä¸ªpivot_tableå¿…é¡»æ‹¥æœ‰ä¸€ä¸ªindexã€‚
  Values    Valueså¯ä»¥å¯¹éœ€è¦çš„è®¡ç®—æ•°æ®è¿›è¡Œç­›é€‰
  Aggfunc   aggfuncå‚æ•°å¯ä»¥è®¾ç½®æˆ‘ä»¬å¯¹æ•°æ®èšåˆæ—¶è¿›è¡Œçš„å‡½æ•°æ“ä½œã€‚å½“æˆ‘ä»¬æœªè®¾ç½®aggfuncæ—¶ï¼Œå®ƒé»˜è®¤aggfunc='mean'è®¡ç®—å‡å€¼ï¼Œå¯ä»¥è®¾ç½®å¤šä¸ª å¦‚ï¼š
            [aggfunc=[np.sum,np.mean]] æ­¤æ—¶ä¼šæ˜¾ç¤ºnp.sumå’Œnp.meanç»Ÿè®¡å‡ºæ¥çš„æ•°æ®ã€‚
            
  Columns   Columnsç±»ä¼¼Indexå¯ä»¥è®¾ç½®åˆ—å±‚æ¬¡å­—æ®µï¼Œå®ƒä¸æ˜¯ä¸€ä¸ªå¿…è¦å‚æ•°ï¼Œä½œä¸ºä¸€ç§åˆ†å‰²æ•°æ®çš„å¯é€‰æ–¹å¼ã€‚

      #ä»¥ Pclass(èˆ¹èˆ±)ä¸ºç´¢å¼• æŸ¥çœ‹ä¸åŒèˆ¹èˆ±äººå‘˜çš„å¹³å‡å­˜æ´»ç‡Survivedã€‚
      train_survived=train_content.pivot_table(index="Pclass",values="Survived")
      
      # æŸ¥çœ‹ä¸åŒèˆ¹èˆ±çš„æ”¶è´¹å‡å€¼æ˜¯å¤šå°‘
      train_age_fare=train_content.pivot_table(index="Pclass",values=["Age","Fare"])
      
      # æŸ¥çœ‹ä¸åŒèˆ¹èˆ±äººå‘˜çš„çš„äººå‡å¹´é¾„
      train_survived=train_content.pivot_table(index="Pclass",values="Age")
  
### icolå’Œcol å–èŒƒå›´
    
  ilocå’Œlocçš„åŒºåˆ«æ˜¯ ilocåªèƒ½è·Ÿæ•´æ•°ï¼Œè€Œlocå¯ä»¥è·Ÿæ•°å­—
   
     print(train_content.iloc[83,3])     #æ‰¾çš„æ˜¯é™¤titleä»¥å¤–çš„ç¬¬84è¡Œï¼Œå› ä¸ºæ•°ç»„é»˜è®¤æ˜¯ä»0å¼€å§‹å‘ä¸Šå¢é•¿çš„
     print(train_content.iloc[82:83,3:5]) #å»å°¾çš„83ä¸åŒ…æ‹¬ 5ä¸åŒ…æ‹¬
     print(train_content.iloc[82:84,3:6]) #å»å°¾çš„83ä¸åŒ…æ‹¬ 5ä¸åŒ…æ‹¬

     print(train_content.loc[83,"Age"])
     print(train_content.loc[82:83,"Name":"Age"])   #è¿˜å¯ä»¥è·ŸèŒƒå›´


### æŸ¥æ‰¾ df æ•°æ®åˆ—ä¸­ åˆ—æ•°æ®ç­‰äº x é•¿åº¦çš„å€¼

    # æ‰¾åˆ°åœ¨ genres åˆ—ä¸­åˆ—é•¿åº¦ç­‰äº7çš„æ•°æ®
    train[train['genres'].str.len() == 7]


### å°†Pandasä¸­çš„DataFrameç±»å‹è½¬æ¢æˆNumpyä¸­arrayç±»å‹çš„ä¸‰ç§æ–¹æ³•
  dataframe è½¬åˆ—è¡¨  
      
      
1ã€ä½¿ç”¨DataFrameä¸­çš„valuesæ–¹æ³•

    df.values
  
2ã€ä½¿ç”¨DataFrameä¸­çš„as_matrix()æ–¹æ³•

    df.as_matrix()

3ã€ä½¿ç”¨Numpyä¸­çš„arrayæ–¹æ³•

    np.array(df)

### pandas.mode() 

__è¿”å›å‡ºç°é¢‘ç‡æœ€é«˜çš„å€¼ é»˜è®¤ axis=0ï¼Œå³æ¯ä¸€ç‰¹å¾ä¸­å‡ºç°æœ€é«˜çš„å€¼ é»˜è®¤å¿½ç•¥NAå€¼ï¼Œå¦‚æœæƒ³å°†NAå€¼è®¡ç®—è¿›å»å¯ä»¥ä½¿ç”¨ dropna=False__

__æ³¨æ„ï¼šå¦‚æœå­˜åœ¨é¢‘ç‡ç›¸åŒçš„å€¼ä¼šè¿”å›ä¸¤ä¸ªå€¼__

__æ•°æ®:__

    >>> df = pd.DataFrame([('bird', 2, 2),
    ...                    ('mammal', 4, np.nan),
    ...                    ('arthropod', 8, 0),
    ...                    ('bird', 2, np.nan)],
    ...                   index=('falcon', 'horse', 'spider', 'ostrich'),
    ...                   columns=('species', 'legs', 'wings'))
    >>> df
              species  legs  wings
    falcon        bird     2    2.0
    horse       mammal     4    NaN
    spider   arthropod     8    0.0
    ostrich       bird     2    NaN  

__ä¾‹å­1__

    >>> df.mode()
      species  legs  wings
    0    bird   2.0    0.0
    1     NaN   NaN    2.0

__ä¾‹å­2__

    >>> df.mode(dropna=False)
      species  legs  wings
    0    bird     2    NaN


### åˆ é™¤ç¼ºå¤±å€¼ï¼šdf.dropna()

    df = pd.DataFrame({"name": ['Alfred', 'Batman', 'Catwoman'],
                      "toy": [np.nan, 'Batmobile', 'Bullwhip'],
                      "born": [pd.NaT, pd.Timestamp("1940-04-25"),
                               pd.NaT]})

    >>> df

          name        toy       born
    0    Alfred        NaN        NaT
    1    Batman  Batmobile 1940-04-25
    2  Catwoman   Bullwhip        NaT

__åˆ é™¤è‡³å°‘ç¼ºå°‘ä¸€ä¸ªå…ƒç´ çš„è¡Œ__

    df.dropna()

       name        toy       born
    1  Batman  Batmobile 1940-04-25


__åˆ é™¤è‡³å°‘ç¼ºå°‘ä¸€ä¸ªå…ƒç´ çš„åˆ—ã€‚__

    df.dropna(axis='columns')

          name
    0    Alfred
    1    Batman
    2  Catwoman

__åˆ é™¤ç¼ºå°‘æ‰€æœ‰å…ƒç´ çš„è¡Œã€‚__

    >>> df.dropna(how='all')

          name        toy       born
    0    Alfred        NaN        NaT
    1    Batman  Batmobile 1940-04-25
    2  Catwoman   Bullwhip        NaT

__ä»…ä¿ç•™è‡³å°‘åŒ…å«2ä¸ªéNAå€¼çš„è¡Œã€‚__

    >>> df.dropna(thresh=2)

          name        toy       born
    1    Batman  Batmobile 1940-04-25
    2  Catwoman   Bullwhip        NaT

__åˆ é™¤æŸåˆ—ä¸­ç¼ºå¤±å€¼ï¼š__

    df['toy'].dropna()

    1    Batmobile
    2     Bullwhip
    Name: toy, dtype: object



### pandas.DataFrame.fillna ç”¨æŒ‡å®šçš„æ–¹æ³•å¡«å……NA/NaN

__DataFrame.fillnaï¼ˆvalue = Noneï¼Œmethod = Noneï¼Œaxis = Noneï¼Œinplace = Falseï¼Œlimit = Noneï¼Œdowncast = Noneï¼Œ** kwargs ï¼‰__
        
  value ï¼š æ ‡é‡ï¼Œå­—å…¸ï¼Œç³»åˆ—æˆ–DataFrameç”¨äºå¡«å……å­”çš„å€¼ï¼ˆä¾‹å¦‚0ï¼‰ï¼Œæˆ–è€…ç”¨äºæŒ‡å®šæ¯ä¸ªç´¢å¼•ï¼ˆå¯¹äºSeriesï¼‰æˆ–åˆ—ï¼ˆå¯¹äºDataFrameï¼‰ä½¿ç”¨å“ªä¸ªå€¼çš„Dict /Series / DataFrameã€‚ï¼ˆä¸ä¼šå¡«å†™dict / Series / DataFrameä¸­çš„å€¼ï¼‰ã€‚è¯¥å€¼ä¸èƒ½æ˜¯åˆ—è¡¨ã€‚
                 
  method :  {'backfill'ï¼Œ'bfill'ï¼Œ'pad'ï¼Œ'ffill'ï¼ŒNone}ï¼Œé»˜è®¤æ—    ç”¨äºå¡«å……é‡æ–°ç´¢å¼•çš„å¡«å……å­”çš„æ–¹æ³•ç³»åˆ—å¡«å……/å¡«å……
              
  axis : {0æˆ–'ç´¢å¼•'ï¼Œ1æˆ–'åˆ—'}
  
  ä¾‹å­ï¼š
  
      >>> df = pd.DataFrame([[np.nan, 2, np.nan, 0],
      ...                    [3, 4, np.nan, 1],
      ...                    [np.nan, np.nan, np.nan, 5],
      ...                    [np.nan, 3, np.nan, 4]],
      ...                    columns=list('ABCD'))
      >>> df
           A    B   C  D
      0  NaN  2.0 NaN  0
      1  3.0  4.0 NaN  1
      2  NaN  NaN NaN  5
      3  NaN  3.0 NaN  4

   __ç”¨0æ›¿æ¢æ‰€æœ‰NaNå…ƒç´ __
   
      >>> df.fillna(0)
          A   B   C   D
      0   0.0 2.0 0.0 0
      2   0.0 0.0 0.0 5
      3   0.0 3.0 0.0 4
      1   3.0 4.0 0.0 1

   __æˆ‘ä»¬è¿˜å¯ä»¥å‘å‰æˆ–å‘åä¼ æ’­éç©ºå€¼ã€‚__

    >>> df.fillna(method='ffill')
        A   B   C   D
    0   NaN 2.0 NaN 0
    1   3.0 4.0 NaN 1
    2   3.0 4.0 NaN 5
    3   3.0 3.0 NaN 4

   __å°†â€œAâ€ï¼Œâ€œBâ€ï¼Œâ€œCâ€å’Œâ€œDâ€åˆ—ä¸­çš„æ‰€æœ‰NaNå…ƒç´ åˆ†åˆ«æ›¿æ¢ä¸º0,1,2å’Œ3ã€‚__

    >>> values = {'A': 0, 'B': 1, 'C': 2, 'D': 3}
    >>> df.fillna(value=values)
        A   B   C   D
    0   0.0 2.0 2.0 0
    1   3.0 4.0 2.0 1
    2   0.0 1.0 2.0 5
    3   0.0 3.0 2.0 4
    
  __åªæ›¿æ¢ç¬¬ä¸€ä¸ªNaNå…ƒç´ ã€‚__

    >>> df.fillna(value=values, limit=1)
        A   B   C   D
    0   0.0 2.0 2.0 0
    1   3.0 4.0 NaN 1
    2   NaN 1.0 NaN 5
    3   NaN 3.0 NaN 4
    
    
### pandas.DataFrame.groupby   
  
  DataFrame.groupby(by=None, axis=0, level=None, as_index=True, sort=True, group_keys=True, squeeze=False, observed=False, **kwargs)[source]

*   __å‚æ•°ä»‹ç»ï¼š__
    
      as_index:ä¸ºTrueæ—¶ä¼šå°†ç¬¬ä¸€åˆ—æ•°æ®è®¾ç½®ä¸ºindexï¼Œä¸ºFalseæ—¶åˆ™ä¼šæ–°å»ºä¸€ä¸ªæ•°å­—ç´¢å¼•ã€‚é»˜è®¤ä¸ºTrue

        import pandas as pd

        df = pd.DataFrame(data={'books':['bk1','bk1','bk1','bk2','bk2','bk3'], 'price': [12,12,12,15,15,17]})

        df

        outï¼š
            books	price
          0  bk1	  12
          1	 bk1	  12
          2	 bk1	  12
          3	 bk2	  15
          4	 bk2	  15
          5	 bk3	  17

        a=df.groupby('books', as_index=True).sum()
        print(a.index)
        a

        outï¼š

          Index(['bk1', 'bk2', 'bk3'], dtype='object', name='books')

                price
          books	
          bk1	    36
          bk2	    30
          bk3	    17

        df.groupby('books', as_index=False).sum() 
        
        outï¼š 

            books	price
          0	bk1	  36
          1	bk2	  30
          2	bk3	  17

    __groupbyæ“ä½œæ¶‰åŠæ‹†åˆ†å¯¹è±¡ï¼Œåº”ç”¨å‡½æ•°å’Œç»„åˆç»“æœçš„æŸç§ç»„åˆã€‚è¿™å¯ç”¨äºå¯¹è¿™äº›ç»„ä¸Šçš„å¤§é‡æ•°æ®å’Œè®¡ç®—æ“ä½œè¿›è¡Œåˆ†ç»„ã€‚__
    
    __ä½¿ç”¨groupbyè¿›è¡Œåˆ‡ç‰‡ä¹‹åï¼Œæˆ‘ä»¬å¦‚æœè¿›è¡Œæ“ä½œå…¶å®æ˜¯åœ¨é‚£ä¸ªåˆ‡ç‰‡(split)ä¸­è¿›è¡Œçš„æ“ä½œï¼Œè®¡ç®—å®Œæˆä¹‹åè¿”å›åˆå¹¶ç»“æœ(Combine) å¦‚å›¾ï¼š__


<div align=center><img width="650" height="300" src="https://raw.githubusercontent.com/OneStepAndTwoSteps/Data_Analysis/master/static/pandas/2.png"/></div>

*   __groupbyå‡½æ•° ä¾‹å­1__

        import pandas as pd
        import numpy as np

        dict_obj = {'key1' : ['a', 'b', 'a', 'b', 
                              'a', 'b', 'a', 'a'],
                    'key2' : ['one', 'one', 'two', 'three',
                              'two', 'two', 'one', 'three'],
                    'data1': np.random.randn(8),
                    'data2': np.random.randn(8)}
        df_obj = pd.DataFrame(dict_obj)
        print(df_obj)

    __outï¼š__

        key1   key2     data1     data2
        0    a    one -0.109110  0.528666
        1    b    one -0.746051  1.994562
        2    a    two  2.685447  1.672294
        3    b  three  0.546663 -0.970285
        4    a    two -0.859890 -0.964093
        5    b    two -0.347244  0.146132
        6    a    one  0.254899  0.830872
        7    a  three -0.958547 -2.016811


*   __dataframeæ ¹æ®key1è¿›è¡Œåˆ†ç»„__                          
                                                                                     
       grouped1=df_obj.groupby('key1')

        [x for x in grouped1]


        [('a',   key1   key2     data1     data2
          0       a    one -0.109110  0.528666
          2       a    two  2.685447  1.672294
          4       a    two -0.859890 -0.964093
          6       a    one  0.254899  0.830872
          7       a  three -0.958547 -2.016811), ('b',   key1   key2     data1     data2
          1       b    one -0.746051  1.994562
          3       b  three  0.546663 -0.970285
          5       b    two -0.347244  0.146132)]

*   __ä½¿ç”¨groupbyæŒ‡å®šå­—æ®µå†…å®¹è¿›è¡Œè¿ç®—__

    __å¦‚ï¼š__

        # æŒ‰ç…§ key1 è¿›è¡Œåˆ†ç»„ä»ä¸Šé¢çš„æ•°æ®ä¸­æˆ‘ä»¬å¯ä»¥å‘ç°åˆ†ä¸ºa,bä¸¤ç»„
        grouped = df.groupby(df['key1'])
        grouped.mean()

    __outï¼š__

        # è¿™é‡Œä½¿ç”¨ df['key1'] åšäº†åˆ†ç»„é”®ï¼Œå³æŒ‰ a å’Œ b è¿›è¡Œåˆ†ç»„ã€‚ä¸‹ä¾‹ä¸­æ²¡æœ‰æ˜¾ç¤º key2 åˆ—ï¼Œæ˜¯å› ä¸ºå…¶å€¼ä¸æ˜¯æ•°å­—ç±»å‹ï¼Œè¢« mean() æ–¹æ³•è‡ªåŠ¨å¿½è§†äº†
            data1	data2
        key1		
        a	0.202560	0.010185
        b	-0.182211	0.390136
        
    __å¦‚ï¼š__ 

        # ä»¥key1è¿›è¡Œåˆ†ç»„ï¼Œå°†data2å­—æ®µä¸­çš„å†…å®¹è¿›è¡Œæ±‚å’Œ
        grouped1=df_obj.groupby(['key1'])['data2'].sum()
        grouped1

    __outï¼š__

        key1
        a    0.050927
        b    1.170409
        Name: data2, dtype: float64

    __å¦‚ï¼š__ æ³¨æ„ä½¿ç”¨groupbyè¿›è¡Œå¤šåˆ—çš„ç»„åˆæ—¶ï¼Œé¡ºåºä¼šå½±å“æˆ‘ä»¬çš„åˆ†ç»„æ•ˆæœ å¦‚groupby(['key1','key2']) å’Œgroupby(['key2','key1'])å±•ç¤ºå‡ºæ¥çš„æ•ˆæœå°±ä¼šä¸åŒ

        # ä»¥key1ï¼Œå’Œkey2 è¿›è¡Œåˆ†ç»„ï¼Œå°†data2å­—æ®µä¸­çš„å†…å®¹è¿›è¡Œæ±‚å’Œ
        grouped1=df_obj.groupby(['key1','key2'])['data2'].sum()
        grouped1

    __outï¼š__

        key1  key2 
        a     one      1.359537
              three   -2.016811
              two      0.708200
        b     one      1.994562
              three   -0.970285
              two      0.146132


    __å¦‚ï¼š__

        # ä»¥Pclassè¿›è¡Œåˆ†ç»„ï¼Œå°†å­—æ®µä¸­'Pclass','Survived'çš„å†…å®¹è¿›è¡Œæ±‚å’Œ
        print(train_data.groupby(['Pclass'])['Pclass','Survived'].mean())
        
                  Pclass    Survived
        Pclass                  
        1          1.0      0.629630
        2          2.0      0.472826
        3          3.0      0.242363
      
        print(train_data.groupby(['Pclass'])['Pclass'ï¼Œ'Survived','Age'].mean())

                  Pclass    Survived        Age
        Pclass                             
        1          1.0      0.629630      37.048118
        2          2.0      0.472826      29.866958
        3          3.0      0.242363      26.403259


*   __åˆ†å±‚ç´¢å¼•__

        æˆ‘ä»¬å¯ä»¥ä½¿ç”¨levelå‚æ•°å¯¹ä¸åŒçº§åˆ«çš„å±‚æ¬¡ç´¢å¼•è¿›è¡Œåˆ†ç»„ï¼š

        >>> arrays = [['Falcon', 'Falcon', 'Parrot', 'Parrot'],
        ...           ['Capitve', 'Wild', 'Capitve', 'Wild']]
        >>> index = pd.MultiIndex.from_arrays(arrays, names=('Animal', 'Type'))
        >>> df = pd.DataFrame({'Max Speed' : [390., 350., 30., 20.]},
        ...                    index=index)
        >>> df
                        Max Speed
        Animal Type
        Falcon Capitve      390.0
              Wild         350.0
        Parrot Capitve       30.0
              Wild          20.0

        >>> df.groupby(level=0).mean()
                Max Speed
        Animal
        Falcon      370.0
        Parrot       25.0

        >>> df.groupby(level=1).mean()
                Max Speed
        Type
        Capitve      210.0
        Wild         185.0

*   __groupby å‡½æ•°çš„ä¸¤ä¸ªæ–¹æ³• .size() .count()__

    å¯ä»¥ä½¿ç”¨ GroupBy å¯¹è±¡ï¼ˆä¸è®ºæ˜¯ DataFrameGroupBy è¿˜æ˜¯ SeriesGroupByï¼‰çš„ .size() æ–¹æ³•æŸ¥çœ‹åˆ†ç»„å¤§å°ï¼š

    __.size å¦‚:__

        grouped.size()

    __outï¼š__

        key1
        a       3
        b       2

    __.count å¦‚ï¼š__

        grouped.count()

    __outï¼š__

            key2	data1	data2
        key1			
        a	  5	    5	    5
        b	  3	    3	    3

    __.size å’Œ .countçš„åŒºåˆ«ï¼š sizeè®¡æ•°æ—¶åŒ…å«NaNå€¼ï¼Œè€Œcountä¸åŒ…å«NaNå€¼__


*   __groupby.first()__

    é¦–å…ˆè®¡ç®—æ¯ç»„ä¸­çš„å€¼

    __ä¾‹å­ï¼š__

        train.groupby('matchId')['matchType'].value_counts()

    __out__

        matchId         matchType       
        0000a43bce5eec  squad-fpp            95
        0000eb01ea6cdd  squad-fpp            98
        0002912fe5ed71  solo                 95
        0003b92987589e  duo                 100
        0006eb8c17708d  duo-fpp              93
        00077604e50a63  squad-fpp            98


    __ä¾‹å­ï¼š__

    é¦–å…ˆä½¿ç”¨ groupby('matchId') ,å°† matchId ä½œä¸ºç´¢å¼•ï¼Œåé¢æ¥ matchType , firstçš„ä½œç”¨åœ¨äºï¼Œå› ä¸º æŸä¸€ä¸ª matchId ä¸‹é¢å¯èƒ½æœ‰å¤šä¸ª matchType ï¼Œè€Œfirst()åªå–ç¬¬ä¸€ä¸ª matchTypeçš„å€¼ ã€‚

        train.groupby('matchId')['matchType'].first().value_counts()

    __out__

        squad-fpp           18576
        duo-fpp             10620
        squad                6658
        solo-fpp             5679
        duo                  3356
        solo                 2297
        normal-squad-fpp      358
        normal-duo-fpp        158
        normal-solo-fpp        96
        crashfpp               73
        flaretpp               29
        normal-solo            23
        normal-squad           16
        normal-duo             12
        flarefpp                9
        crashtpp                5
        Name: matchType, dtype: int64

### pd.to_frame

pd.to_frame å°† Series è½¬åŒ–ä¸º dataframe

*   __ä¾‹å­__

        train.groupby(['matchType','matchId']).count().groupby(['matchType','matchId']).size().shape
      
        group = train.groupby(['matchType','matchId','groupId']).count().groupby(['matchType','matchId']).size().to_frame('groups in match')
        print(group)

        group.shape
    __out__

        (47965,)

                              groups in match
        matchType	  matchId	
        duo	        0003b92987589e	  47
                    0006eb8c17708d	  44
                    00086c74bb4efc	  48
        (47965,1)

    æˆ‘ä»¬å¯ä»¥é€šè¿‡ shape æŸ¥çœ‹ä»–åˆ°åº•æ˜¯ä¸æ˜¯ seriesï¼Œåªæœ‰ series æ‰å¯ä»¥è¿›è¡Œ to_farme.




### pd.cut ä¸ºæ•°æ®åˆ†æ®µï¼š

  éœ€è¦å°†æ•°æ®å€¼åˆ†æ®µå¹¶æ’åºåˆ°ç®±ä¸­æ—¶ä½¿ç”¨cutã€‚æ­¤å‡½æ•°å¯¹äºä»è¿ç»­å˜é‡è½¬æ¢ä¸ºåˆ†ç±»å˜é‡ä¹Ÿå¾ˆæœ‰ç”¨ã€‚ä¾‹å¦‚ï¼Œcutå¯ä»¥å°†å¹´é¾„è½¬æ¢ä¸ºå¹´é¾„èŒƒå›´ç»„ã€‚æ”¯æŒåˆ†ç®±åˆ°ç›¸åŒæ•°é‡çš„ç®±æŸœæˆ–é¢„å…ˆæŒ‡å®šçš„ç®±æŸœé˜µåˆ—ã€‚

  pandas.cutï¼ˆxï¼Œbinsï¼Œright = Trueï¼Œlabels = Noneï¼Œretbins = Falseï¼Œprecision = 3ï¼Œinclude_lowest = Falseï¼Œduplicates ='raise' ï¼‰

__å‚æ•°ä»‹ç»ï¼š__
    
    x: æ•°æ®
    
    binsï¼šè¿›è¡Œåˆ’åˆ†çš„ä¸€ç»´æ•°ç»„
      
      å½“ bins ä¸º æ•´æ•°æ—¶,å°†xåˆ’åˆ†ä¸ºå¤šå°‘ä¸ªç­‰é—´è·çš„åŒºé—´

      å½“ bins ä¸º åºåˆ—æ—¶,å°†xåˆ’åˆ†åœ¨æŒ‡å®šçš„åºåˆ—ä¸­ï¼Œè‹¥ä¸åœ¨è¯¥åºåˆ—ä¸­ï¼Œåˆ™æ˜¯NaN

    rightï¼šæ˜¯å¦åŒ…å«å³ç«¯ç‚¹

    labels : æ˜¯å¦ç”¨æ ‡è®°æ¥ä»£æ›¿è¿”å›çš„bins

    precision: ç²¾åº¦

    include_lowest:æ˜¯å¦åŒ…å«å·¦ç«¯ç‚¹

__ä¾‹å­ï¼š__

*   å½“binsä¸ºæ•´æ•°æ—¶ï¼šå°†æ•°æ®åˆ†ä¸ºä¸‰ä»½ç­‰é—´è·çš„åŒºé—´

      pd.cut(np.array([1, 7, 5, 4, 6, 3]), 3)

          [(0.994, 3.0], (5.0, 7.0], (3.0, 5.0], (3.0, 5.0], (5.0, 7.0], (0.994, 3.0]]  # è¾“å‡ºçš„æ•°æ®åŒºé—´åˆ’åˆ†
          Categories (3, interval[float64]): [(0.994, 3.0] < (3.0, 5.0] < (5.0, 7.0]]   # 3ä»½ç­‰é—´è·åŒºé—´

*   å½“binsä¸ºä»¥åºåˆ—æ—¶ï¼Œå¯ä»¥çœ‹åˆ°1ä¸å±äºæˆ‘ä»¬2-4åŒºé—´ï¼Œä¹Ÿä¸å±äº4-6åŒºé—´ï¼Œä¹Ÿä¸å±äº6-8åŒºé—´ï¼Œæ‰€ä»¥è¾“å‡ºçš„å†…å®¹ä¸ºNAN

        pd.cut(np.array([1, 7, 5, 4, 6, 3]), [2,4,6,8]) 

          [NaN, (6.0, 8.0], (4.0, 6.0], (2.0, 4.0], (4.0, 6.0], (2.0, 4.0]]
          Categories (3, interval[int64]): [(2, 4] < (4, 6] < (6, 8]]

*   ç»™ä¸åŒåŒºé—´èµ‹å€¼

        pd.cut(np.array([1, 7, 5, 4, 6, 3]), [2,4,6,8],labels=['2åˆ°4åŒºé—´','4åˆ°6åŒºé—´','6åˆ°8åŒºé—´']) 
        
          [NaN, 6åˆ°8åŒºé—´, 4åˆ°6åŒºé—´, 2åˆ°4åŒºé—´, 4åˆ°6åŒºé—´, 2åˆ°4åŒºé—´]
          Categories (3, object): [2åˆ°4åŒºé—´ < 4åˆ°6åŒºé—´ < 6åˆ°8åŒºé—´]

  ### pandasæŒ‰è‹¥å¹²ä¸ªåˆ—çš„ç»„åˆæ¡ä»¶ç­›é€‰æ•°æ®
    #å–å¹´é¾„ç­‰äº26ï¼Œå¹¶ä¸”å­˜æ´»çš„æ•°æ®çš„æ•°é‡
    print(train_data[(train_data['Age']==29) & (train_data['Survived']==1)].count())

  ### pandasä¸€æ¬¡æ˜¾ç¤ºæŒ‡å®šçš„å¤šä¸ªæ ‡ç­¾ 
    #ä½¿ç”¨ [[ ]] ä¸¤å±‚åµŒå¥—æ‹¬å· æ¯”å¦‚ 
    print(train_data[['Survived','Age']])
    print("%s "%(new_user_data[new_user_data['èŠ‚']==section][['åå­—','çŸ¥è¯†ç‚¹']].values))


  ### ç­›é€‰å‡ºç‰¹å®šå­—ç¬¦ä¸²çš„åˆ—

    [col for col in train.columns if 'str' in col]

  ### è¿‡æ»¤å‡ºåŒ…å«æŸä¸ªå­—ç¬¦ä¸²çš„åˆ—ä¿¡æ¯ df.filter()

    #è¿‡æ»¤å‡ºåŒ…å« matchType å­—ç¬¦ä¸²çš„æ‰€æœ‰åˆ—
    matchType_encoding = train.filter(regex='matchType')

  ### pandas.Series.map
    
    æ ¹æ®è¾“å…¥çš„å¯¹åº”å…³ç³»æ˜ å°„ç³»åˆ—çš„å€¼ã€‚

    ç”¨äºå°†ç³»åˆ—ä¸­çš„æ¯ä¸ªå€¼æ›¿æ¢ä¸ºå¦ä¸€ä¸ªå€¼ï¼Œè¯¥å€¼å¯ä»¥ä»å‡½æ•°ï¼Œa dictæˆ–a æ´¾ç”ŸSeriesã€‚
  
  __ä¾‹å­ï¼š__
  
      >>> s = pd.Series(['cat', 'dog', np.nan, 'rabbit'])
      >>> s
      0      cat
      1      dog
      2      NaN
      3   rabbit
      dtype: object
  
  mapæ¥å—a dictæˆ–a Seriesã€‚é™¤édictå…·æœ‰é»˜è®¤å€¼ï¼ˆä¾‹å¦‚ï¼‰ï¼Œå¦åˆ™å°†dictè½¬æ¢ä¸ºæœªæ‰¾åˆ°çš„NaNå€¼defaultdictï¼š
  
      >>> s.map({'cat': 'kitten', 'dog': 'puppy'})
      0   kitten
      1    puppy
      2      NaN
      3      NaN
      dtype: object
      
  __å®ƒè¿˜æ¥å—ä¸€ä¸ªåŠŸèƒ½ï¼š__

    >>> s.map('I am a {}'.format)
    0       I am a cat
    1       I am a dog
    2       I am a nan
    3    I am a rabbit
    dtype: object
  
  ä¸ºé¿å…å°†å‡½æ•°åº”ç”¨äºç¼ºå¤±å€¼ï¼ˆå¹¶å°†å…¶ä¿ç•™ä¸º NaNï¼‰ï¼Œna_action='ignore'å¯ä»¥ä½¿ç”¨ï¼š

    >>> s.map('I am a {}'.format, na_action='ignore')
    0     I am a cat
    1     I am a dog
    2            NaN
    3  I am a rabbit
    dtype: object

  ### pandas to_dict

  __ä¾‹å­ï¼š__
    
    train_feature=vec.fit_transform(data.to_dict(orient='record'))

    orientå‚æ•°ä¸åŒä¼šæœ‰ä¸ä¸€æ ·çš„æ•ˆæœ 

    https://blog.csdn.net/m0_37804518/article/details/78444110


    
  ### python dataframe è·å¾— åˆ—åcolumns å’Œè¡Œåç§° index
   
    dfname._stat_axis.values.tolist()   ==  dfname.index.values.tolist()      # è¡Œåç§°
     
    
    dfname.columns.values.tolist()    # åˆ—åç§°

  ### python dataframe å½“è¯»å–csvæ–‡ä»¶ï¼Œä½†csvæ•°æ®ä¸­æ— åˆ—åæ—¶è¿›è¡Œèµ‹å€¼åˆ—å

  __é”™è¯¯ç¤ºèŒƒï¼š__

    data=pd.read_csv('filepath')
    # ä¸ºæ•°æ®å¢åŠ ä¸€è¡Œåˆ—å
    column=['user_id','åå­—','çŸ¥è¯†ç‚¹','èŠ‚','è¯¾ç¨‹','course_id']
    data.columns=column

  __æ­£ç¡®ç¤ºèŒƒï¼š__

    data=pd.read_csv('filepath'ï¼Œheader=None)
    # ä¸ºæ•°æ®å¢åŠ ä¸€è¡Œåˆ—å
    column=['user_id','åå­—','çŸ¥è¯†ç‚¹','èŠ‚','è¯¾ç¨‹','course_id']
    data.columns=column

  ä¸åŠ  header=None ï¼Œåœ¨è¿›è¡Œread_csvä¹‹åï¼Œé»˜è®¤ä¼šå°†ç¬¬ä¸€è¡Œæ•°æ®è®¾ç½®ä¸ºåˆ—åï¼Œæ­¤æ—¶å¦‚æœç›´æ¥è¿›è¡Œ data.columns=column é‚£ä¹ˆç¬¬ä¸€è¡Œæ•°æ®è¢«æ›¿æ¢æˆæˆ‘ä»¬æŒ‡å®šçš„åˆ—åï¼Œè¿™æ ·æˆ‘ä»¬çš„æ•°æ®å°±å˜å°‘äº†ï¼Œå¦‚æœåŠ ä¸Šäº†header=None,é‚£ä¹ˆè¯»å–ä¹‹åçš„æ•°æ®æ˜¯æ²¡æœ‰åˆ—åçš„(ç¬¬ä¸€è¡Œæ•°æ®è¿˜æ˜¯æ•°æ®ï¼Œä¸ä¼šæˆä¸ºåˆ—å)ï¼Œæ­¤æ—¶æˆ‘ä»¬è¿›è¡Œå‘½ååˆ—åå°±ä¸ä¼šæ›¿æ¢æ‰æˆ‘ä»¬çš„æ•°æ®ã€‚


  ### æ„é€ DataFrame

   __ä¾‹å­ï¼š__ å¦‚æœæƒ³è¦æ„é€ è¿™æ ·çš„dataframeï¼š

   <div align=center><img src="https://raw.githubusercontent.com/OneStepAndTwoSteps/data_mining_analysis/master/static/pandas/1.jpg"/></div> 

      import pandas as pd

      list1=[[1,2,3],[4,5,6],[7,8,9]]

      dict={'id':[1,2,3],'item':[[5,6,7,8],[1,2,3],[4,5,6]]}

      data=pd.DataFrame(data=dict,columns=['id','item'])

      print(data)


  ### pandas é”™è¯¯è­¦å‘Šï¼š

    åœ¨ä½¿ç”¨pd.read_csv()æ—¶ å‡ºç°äº†å¦‚ä¸‹çš„é”™è¯¯

      data=pd.read_csv(file_path)

      pandas.errors.ParserError: Error tokenizing data. C error: Expected 20 fields in line 4, saw 21

  __è§£å†³æ–¹æ¡ˆ1ï¼š__ åŠ ä¸Šåˆ†éš”ç¬¦ sep 

      data=pd.read_csv(file_path,sep='\t')

  __è§£å†³æ–¹æ¡ˆ2ï¼š__ å¿½ç•¥é”™è¯¯çš„è¡Œ

      data=pd.read_csv(file_path,error_bad_lines=False)

  


  ### æ•°æ®çš„ååº¦å’Œå³°åº¦

  __df.skew()  ååº¦__

    Definition:æ˜¯æè¿°æ•°æ®åˆ†å¸ƒå½¢æ€çš„ç»Ÿè®¡é‡ï¼Œå…¶æè¿°çš„æ˜¯æŸæ€»ä½“å–å€¼åˆ†å¸ƒçš„å¯¹ç§°æ€§ï¼Œç®€å•æ¥è¯´å°±æ˜¯æ•°æ®çš„ä¸å¯¹ç§°ç¨‹åº¦ã€‚
    ååº¦æ˜¯ä¸‰é˜¶ä¸­å¿ƒè·è®¡ç®—å‡ºæ¥çš„ã€‚
    ï¼ˆ1ï¼‰Skewness = 0 ï¼Œåˆ†å¸ƒå½¢æ€ä¸æ­£æ€åˆ†å¸ƒååº¦ç›¸åŒã€‚
    ï¼ˆ2ï¼‰Skewness > 0 ï¼Œæ­£åå·®æ•°å€¼è¾ƒå¤§ï¼Œä¸ºæ­£åæˆ–å³åã€‚é•¿å°¾å·´æ‹–åœ¨å³è¾¹ï¼Œæ•°æ®å³ç«¯æœ‰è¾ƒå¤šçš„æç«¯å€¼ã€‚
    ï¼ˆ3ï¼‰Skewness < 0 ï¼Œè´Ÿåå·®æ•°å€¼è¾ƒå¤§ï¼Œä¸ºè´Ÿåæˆ–å·¦åã€‚é•¿å°¾å·´æ‹–åœ¨å·¦è¾¹ï¼Œæ•°æ®å·¦ç«¯æœ‰è¾ƒå¤šçš„æç«¯å€¼ã€‚
    ï¼ˆ4ï¼‰æ•°å€¼çš„ç»å¯¹å€¼è¶Šå¤§ï¼Œè¡¨æ˜æ•°æ®åˆ†å¸ƒè¶Šä¸å¯¹ç§°ï¼Œåæ–œç¨‹åº¦å¤§ã€‚


  __df.kurt()  å³°åº¦__

    Definition:ååº¦æ˜¯æè¿°æŸå˜é‡æ‰€æœ‰å–å€¼åˆ†å¸ƒå½¢æ€é™¡ç¼“ç¨‹åº¦çš„ç»Ÿè®¡é‡ï¼Œç®€å•æ¥è¯´å°±æ˜¯æ•°æ®åˆ†å¸ƒé¡¶çš„å°–é”ç¨‹åº¦ã€‚
    å³°åº¦æ˜¯å››é˜¶æ ‡å‡†çŸ©è®¡ç®—å‡ºæ¥çš„ã€‚
    ï¼ˆ1ï¼‰Kurtosis=0 ä¸æ­£æ€åˆ†å¸ƒçš„é™¡ç¼“ç¨‹åº¦ç›¸åŒã€‚
    ï¼ˆ2ï¼‰Kurtosis>0 æ¯”æ­£æ€åˆ†å¸ƒçš„é«˜å³°æ›´åŠ é™¡å³­â€”â€”å°–é¡¶å³°
    ï¼ˆ3ï¼‰Kurtosis<0 æ¯”æ­£æ€åˆ†å¸ƒçš„é«˜å³°æ¥å¾—å¹³ç¼“â€”â€”å¹³é¡¶å³°

  ### pandas è®¡ç®—çŸ©é˜µå…³ç³»ç³»æ•°

  ä½¿ç”¨.corr() å¯ä»¥ç”¨äºè®¡ç®—çŸ©é˜µå…³ç³»ç³»æ•°ï¼Œå¯ä»¥ä½¿ç”¨å¾—åˆ°çš„å…³ç³»ç³»æ•°ç»˜åˆ¶çƒ­åŠ›å›¾
    
  __ä¸¾ä¾‹ï¼š__

    ç°åœ¨æˆ‘ä»¬æœ‰ä¸€äº›æ•°æ®ï¼Œæˆ‘ä»¬è¦è®¡ç®—è¿™äº›ç‰¹å¾ä¹‹é—´çš„å…³ç³»
    
    corrmat = train_data.drop('Id',axis=1).corr()   # train_data æ˜¯read_cav()è¯»å–è¿›æ¥çš„æ•°æ®
    corrmat

  __out__

    	            MSSubClass	LotFrontage	  LotArea	 OverallQual  OverallCond

    MSSubClass	  1.000000	  -0.386347	  -0.139781	  0.032628	  -0.059316	
    LotFrontage	  -0.386347 	1.000000	  0.426095	  0.251646	  -0.059213	
    LotArea	      -0.139781	  0.426095	  1.000000	  0.105806	  -0.005636	
    OverallQual	  0.032628	  0.251646  	0.105806	  1.000000	  -0.091932	
    OverallCond   -0.059316	  -0.059213	  -0.005636 	-0.091932	  1.000000	

  __ç»˜åˆ¶çƒ­åŠ›å›¾__

    fig,ax=plt.subplots(figsize=(20,16))
    sns.heatmap(corrmat,annot=True,fmt ='.1')
    plt.show()


### df.to_sql dfå†™åˆ°æ•°æ®åº“ï¼š

  å°†dfæ•°æ®å†™å…¥æ•°æ®åº“

__æ¡ˆä¾‹ï¼š__

    import MySQLdb
    import pandas as pd
    from sqlalchemy import create_engine

    host = '127.0.0.1'
    port = 3306
    db = 'db_name'
    user = 'db_user'
    password = 'db_user_password'
    
    # ?charset=utf8 è¡¨ç¤ºä½¿ç”¨utf8å­—ç¬¦é›†
    engine = create_engine(str(r"mysql+mysqldb://%s:" + '%s' + "@%s/%s?charset=utf8") % (user, password, host, db))

    try:
        # å°†æ•°æ®å†™å…¥test1è¡¨ï¼Œå¦‚æœè¡¨å­˜åœ¨å°±è¿›è¡Œæ›¿æ¢ï¼Œå¦‚æœæ•°æ®åº“çš„ç¼–ç æ ¼å¼ä¸ºlatinï¼Œå¹¶ä¸”æ•°æ®ä¸­å­˜åœ¨ä¸­æ–‡ï¼Œä¼šæŠ¥ä¹±ç ã€‚
        Associate_dknowledge.to_sql('test1',con=engine,if_exists='replace',index=False)
    except Exception as e:
        print(e)

__df.to_sqlæš‚æ—¶è¿˜ä¸æ”¯æŒæˆ‘ä»¬è®¾ç½®ä¸»é”®__

    å¦‚æœæƒ³è¦è®¾ç½®ä¸»é”®ï¼šåŠ ä¸Š æ ‡è®°ä¸º <---- çš„ä¸¤å¥

    import MySQLdb
    import pandas as pd
    from sqlalchemy import create_engine

    host = '127.0.0.1'
    port = 3306
    db = 'db_name'
    user = 'db_user'
    password = 'db_user_password'
    
    # ?charset=utf8 è¡¨ç¤ºä½¿ç”¨utf8å­—ç¬¦é›†
    engine = create_engine(str(r"mysql+mysqldb://%s:" + '%s' + "@%s/%s?charset=utf8") % (user, password, host, db))
    conn = engine.connect()     <-------

    try:
        # å°†æ•°æ®å†™å…¥test1è¡¨ï¼Œå¦‚æœè¡¨å­˜åœ¨å°±è¿›è¡Œæ›¿æ¢ï¼Œå¦‚æœæ•°æ®åº“çš„ç¼–ç æ ¼å¼ä¸ºlatinï¼Œå¹¶ä¸”æ•°æ®ä¸­å­˜åœ¨ä¸­æ–‡ï¼Œä¼šæŠ¥ä¹±ç ã€‚
        Associate_dknowledge.to_sql('test1',con=engine,if_exists='replace',index=True)
        conn.execute('alter table `{}` add primary key(`index`)'.format(file_name))       <-------

    except Exception as e:
        print(e)


__df.to_sql if_exists='append' æ—¶é˜²æ­¢ä¸»é”®å†²çª__
  
  ä¸ºäº†é˜²æ­¢ä¸»é”®é‡å¤ï¼Œäºæ˜¯æˆ‘ä»¬ä¿®æ”¹åŸå…ˆçš„æ•°æ®ä¸­çš„indexï¼Œè®©å…¶æ¥ç€æ•°æ®åº“ä¸­æœ€å¤§indexå¾€ä¸‹æ’åº

    import MySQLdb
    import pandas as pd
    from sqlalchemy import create_engine

    host = '127.0.0.1'
    port = 3306
    db = 'db_name'
    user = 'db_user'
    password = 'db_user_password'

    engine = create_engine(str(r"mysql+mysqldb://%s:" + '%s' + "@%s/%s?charset=utf8") % (user, password, host, db))
    conn = engine.connect()
    Session = sessionmaker(bind=engine)

    def df_to_sql(test1,data,flag): 
        session = Session(bind=conn)
        # é€šè¿‡flagè¡¨ç¤ºæ˜¯å¦æ›´æ–°è¡¨ï¼Œå¦‚æœæ›´æ–°å°±æ›¿æ¢ä¹‹å‰çš„è¡¨ï¼Œå¦åˆ™è¿½åŠ 
        print('flag: ',flag)
        # å¦‚æœæ˜¯æ›´æ–°è¡¨ï¼Œåˆ™è¦†ç›–åŸæœ‰è¡¨
        if flag==True:
            method='replace'
            data.to_sql(test1,con=engine,if_exists=method,index=True)
        # å¦‚æœæ˜¯è¿½åŠ æ•°æ®ï¼Œåˆ™è¿½åŠ 
        else:
            method='append'
            try:
                result=session.execute('SELECT COUNT(*) FROM `test1`') 
                """ ä¸ºäº†é˜²æ­¢ä¸»é”®é‡å¤ï¼Œäºæ˜¯æˆ‘ä»¬ä¿®æ”¹åŸå…ˆçš„æ•°æ®ä¸­çš„indexï¼Œè®©å…¶æ¥ç€æ•°æ®åº“ä¸­æœ€å¤§indexå¾€ä¸‹æ’åº"""
                data_len=len(data)
                sql_data_len=result.fetchall()[0][0]
                data.index=np.arange(sql_data_len, sql_data_len+data_len)
                print(data)
                data.to_sql(test1,con=engine,if_exists=method,index=True)
                session.commit()
                session.close()
            except Exception as e:
                print(e)


    def set_primary_key(course_name):
      try:
          conn.execute('alter table test1 add primary key(`index`)') 
      except Exception as e:
          print(e)

#### æ³¨æ„ï¼š

è¿™é‡Œæˆ‘ä»¬æœ€å¥½ä½¿ç”¨sessionä¼šè¯ï¼Œè¿™æ ·æˆ‘ä»¬è¿›è¡Œä¸€æ¬¡ä¿®æ”¹ä¹‹åå°±ä¼šæäº¤ä¸€æ¬¡äº‹åŠ¡ï¼Œå¦åˆ™å¯èƒ½é€ æˆäº‹åŠ¡æœªæäº¤çš„æƒ…å†µï¼Œè¿™ä¸ªæ—¶å€™å¦‚æœæˆ‘ä»¬è¿˜ç•™æœ‰äº‹åŠ¡ï¼Œä½†æ˜¯æ­¤æ—¶å¦‚æœæˆ‘ä»¬è¦è¿›è¡Œè¡¨çš„æ›¿æ¢replaceï¼Œé‚£ä¹ˆå› ä¸ºä¹‹å‰å­˜åœ¨äº‹åŠ¡ï¼Œä½†æ˜¯æˆ‘ä»¬è¦å°è¯•å»åˆ è¡¨ï¼Œå°±ä¼šé€ æˆmetadata lockï¼Œå°±ä¼šé˜»å¡ï¼Œæ‰€ä»¥æˆ‘ä»¬é‡‡ç”¨sessionï¼ŒåŠæ—¶è¿›è¡Œäº‹åŠ¡çš„æäº¤ã€‚



### æ•°æ®åº“æ•°æ®è½¬ä¸ºdfï¼š

    import pandas as pd
    import pymysql
    import sqlalchemy
    from sqlalchemy import create_engine

    host = '127.0.0.1'
    port = 3306
    db = 'db_name'
    user = 'db_user'
    password = 'db_user_password'

    # 1. ç”¨sqlalchemyæ„å»ºæ•°æ®åº“é“¾æ¥engine
    engine = create_engine(str(r"mysql+mysqldb://%s:" + '%s' + "@%s/%s?charset=utf8") % (user, password, host, db))
    # sql å‘½ä»¤
    sql_cmd = "SELECT * FROM table"
    df = pd.read_sql(sql=sql_cmd, con=engine)

    # 2. ç”¨DBAPIæ„å»ºæ•°æ®åº“é“¾æ¥engine
    con = pymysql.connect(host=localhost, user=username, password=password, database=dbname, charset='utf8', use_unicode=True)
    df = pd.read_sql(sql_cmd, con)

  


  ### pandasçš„æ‹¼æ¥å¾ªç¯ï¼š

  ä¸¾ä¸ªä¾‹å­ï¼š

    ç°åœ¨æœ‰ä¸¤ä¸ªdfæ•°æ® train_df å’Œ test_df 

    ç°åœ¨ combine=[train_df,test_df]

    for dataset in combine:
        dataset['Title']=dataset.Name.str.extract('([A-Za-z]+)\.',expand=False)

  è¿™é‡Œçš„ for dataset in combine å…¶å®åªæ˜¯å¾ªç¯äº†ä¸¤æ¬¡ï¼Œç¬¬ä¸€æ¬¡æ˜¯train_data ç¬¬äºŒæ¬¡æ˜¯test_dataæ•°æ®ï¼Œå…¶å®ä¸Šå°±æ˜¯æ“ä½œä¿®æ”¹æˆ‘ä»¬train_dataå’Œtest_dataï¼Œä¹‹åè¾“å‡ºtrain_df æˆ‘ä»¬ä¼šå‘ç°å…¶å¤šäº†ä¸€ä¸ªç‰¹å¾ â€˜Titleâ€™ ã€‚

### df.copy()

  __å¤åˆ¶æ­¤å¯¹è±¡çš„ç´¢å¼•å’Œæ•°æ®ã€‚__

  å½“deep=Trueï¼ˆé»˜è®¤ï¼‰æ—¶ï¼Œå°†ä½¿ç”¨è°ƒç”¨å¯¹è±¡çš„æ•°æ®å’Œç´¢å¼•çš„å‰¯æœ¬åˆ›å»ºæ–°å¯¹è±¡ã€‚å¯¹å‰¯æœ¬çš„æ•°æ®æˆ–ç´¢å¼•çš„ä¿®æ”¹ä¸ä¼šåæ˜ åœ¨åŸå§‹å¯¹è±¡ä¸­ï¼ˆè¯·å‚é˜…ä¸‹é¢çš„æ³¨é‡Šï¼‰ã€‚

  ä½•æ—¶deep=Falseï¼Œå°†åˆ›å»ºä¸€ä¸ªæ–°å¯¹è±¡è€Œä¸å¤åˆ¶è°ƒç”¨å¯¹è±¡çš„æ•°æ®æˆ–ç´¢å¼•ï¼ˆä»…å¤åˆ¶å¯¹æ•°æ®å’Œç´¢å¼•çš„å¼•ç”¨ï¼‰ã€‚å¯¹åŸå§‹æ•°æ®çš„ä»»ä½•æ›´æ”¹éƒ½å°†åæ˜ åœ¨æµ…å±‚å‰¯æœ¬ä¸­ï¼ˆåä¹‹äº¦ç„¶ï¼‰ã€‚

  __ä¾‹å­ï¼š__

    a=train_data['Survived']
    b=train_data['Survived']
    print(a.tail())
    print(b.tail())
    
    a:                             b:

    886    0                      886    0
    887    1                      887    1
    888    0                      888    0
    889    1                      889    1
    890    0                      890    0
    Name: Survived, dtype: int64  Name: Survived, dtype: int64
    
__ç°åœ¨æˆ‘ä»¬æ²¡æœ‰è¿›è¡Œdeepcopyï¼Œæˆ‘ä»¬ä¿®æ”¹bçš„æ•°æ®ï¼Œaçš„æ•°æ®ä¹Ÿä¼šå‘ç”Ÿä¿®æ”¹ï¼Œæ‰€ä»¥æˆ‘ä»¬å¦‚æœè¦ä¿æŒaå’Œbæ•°æ®ç‹¬ç«‹ï¼Œæˆ‘ä»¬å¿…é¡»deepcopy__

    b['haha']=1           
    b.tail(1)

    haha    1
    Name: Survived, dtype: int64
    
    a.tail(1)

    haha    1
    Name: Survived, dtype: int64
      
__å¦‚æœè¦ä½¿ç”¨deepcopyï¼Œä½¿ç”¨df.copy(deep=True)å³å¯__


### df è¿½åŠ æ•°æ®

__ä¾‹å­ï¼š__

    df = df.append(df2)
    


### df.quantile
####  åˆ†ä½æ•°è§£é‡Š

__å››åˆ†ä½æ•°__

__æ¦‚å¿µï¼š__ æŠŠç»™å®šçš„ä¹±åºæ•°å€¼ç”±å°åˆ°å¤§æ’åˆ—å¹¶åˆ†æˆå››ç­‰ä»½ï¼Œå¤„äºä¸‰ä¸ªåˆ†å‰²ç‚¹ä½ç½®çš„æ•°å€¼å°±æ˜¯å››åˆ†ä½æ•°ã€‚

__ç¬¬1å››åˆ†ä½æ•° (Q1)__ï¼Œ åˆç§°â€œè¾ƒå°å››åˆ†ä½æ•°â€ï¼Œç­‰äºè¯¥æ ·æœ¬ä¸­æ‰€æœ‰æ•°å€¼ç”±å°åˆ°å¤§æ’åˆ—åç¬¬25%çš„æ•°å­—ã€‚

__ç¬¬2å››åˆ†ä½æ•° (Q2)__ï¼Œåˆç§°â€œä¸­ä½æ•°â€ï¼Œç­‰äºè¯¥æ ·æœ¬ä¸­æ‰€æœ‰æ•°å€¼ç”±å°åˆ°å¤§æ’åˆ—åç¬¬50%çš„æ•°å­—ã€‚

__ç¬¬3å››åˆ†ä½æ•° (Q3)__ï¼Œåˆç§°â€œè¾ƒå¤§å››åˆ†ä½æ•°â€ï¼Œç­‰äºè¯¥æ ·æœ¬ä¸­æ‰€æœ‰æ•°å€¼ç”±å°åˆ°å¤§æ’åˆ—åç¬¬75%çš„æ•°å­—ã€‚

__å››åˆ†ä½è·__ï¼ˆInterQuartile Range, IQRï¼‰= ç¬¬3å››åˆ†ä½æ•°ä¸ç¬¬1å››åˆ†ä½æ•°çš„å·®è·

*   __ç¡®å®špåˆ†ä½æ•°ä½ç½®çš„ä¸¤ç§æ–¹æ³•__

    position = (n+1)*p    - ç®±å‹å›¾é‡‡ç”¨çš„è®¡ç®—æ–¹æ³•

    position = 1 + (n-1)*p  - pythonä¸­è®¡ç®—åˆ†ä½æ•°ä½ç½®çš„æ–¹æ¡ˆ

    å…¶ä¸­ n è¡¨ç¤ºåºåˆ—ä¸­åŒ…å«çš„é¡¹æ•°ã€‚ä¹Ÿå°±æ˜¯æœ‰å¤šå°‘ä¸ªæ•°ã€‚

åœ¨pythonä¸­è®¡ç®—åˆ†ä½æ•°ä½ç½®çš„æ–¹æ¡ˆé‡‡ç”¨ __position=1+(n-1)*p__

__æ¡ˆä¾‹1__

    import pandas as pd
    import numpy as np
    df = pd.DataFrame(np.array([[1, 1], [2, 10], [3, 100], [4, 100]]), columns=['a', 'b'])
    print("æ•°æ®åŸå§‹æ ¼å¼ï¼š")
    print(df)
    print("è®¡ç®—p=0.1æ—¶ï¼Œaåˆ—å’Œbåˆ—çš„åˆ†ä½æ•°")
    print(df.quantile(.1))

__data:__

    åºå·	a	   b
    0	    1	  2
    1	    2	  10
    2	    3	  100
    3	    4	  100

__ç¨‹åºè®¡ç®—ç»“æœï¼š__

    è®¡ç®—p=0.1æ—¶ï¼Œaåˆ—å’Œbåˆ—çš„åˆ†ä½æ•°
    a 1.3
    b 3.7
    Name: 0.1, dtype: float64

__æ‰‹ç®—è®¡ç®—ç»“æœï¼š__

    è®¡ç®—aåˆ—
    pos = 1 + (4 - 1)*0.1 = 1.3
    fraction = 0.3
    ret = 1 + (2 - 1) * 0.3 = 1.3
    è®¡ç®—båˆ—
    pos = 1.3
    ret = 2 + (10 - 2)* 0.3 = 4.4

__è§£é‡Šï¼š__

1ã€é¦–å…ˆæ ¹æ®å…¬å¼ <position=1+(n-1)*p> ï¼Œå› ä¸ºaåˆ—æœ‰ 4ä¸ªé¡¹æ•°ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥å¾—åˆ° pos = 1 + (4 - 1)*0.1 = 1.3 ã€‚

2ã€ç„¶å fraction æ˜¯posçš„åˆ†æ•°ä½ï¼Œå³0.3ã€‚

3ã€æ¥ç€ æˆ‘ä»¬å°†æ•°æ®è¿›è¡Œæ’åºï¼Œå› ä¸ºæˆ‘ä»¬è¿™é‡Œå°±æ˜¯å·²ç»æ’åºå®Œæˆçš„æ•°æ®äº†ï¼Œå°±å¿½ç•¥è¿™ä¸€æ­¥ã€‚

4ã€å› ä¸º posä¸º 1.3ï¼Œé¡¹æ•°ä½ç½®åœ¨ ç¬¬ä¸€é¡¹ å’Œ ç¬¬äºŒé¡¹ ä¹‹é—´ ( 1< 1.3 <2 )

5ã€æ‰€ä»¥é‚£ i å°±æ˜¯ 2 ï¼Œj å°±æ˜¯10ï¼Œä¹Ÿå°±æ˜¯båˆ—è¡¨ä¸­çš„ç¬¬ä¸€é¡¹ 2 å’Œç¬¬äºŒä¸ªé¡¹ 10 ã€‚

6ã€ç„¶åæˆ‘ä»¬å°±å¯ä»¥è¿”å› .1åˆ†ä½æ•°çš„å€¼ï¼Œä¹Ÿå°±æ˜¯ i + (j-i) * fraction = ret = 2 + (10 - 2)* 0.3 = 4.4 ï¼Œä¹Ÿå°±æ˜¯å‰ 10% çš„æ•°æ®ã€‚

__æ¡ˆä¾‹2__

    import pandas as pd
    import numpy as np
    dt = pd.Series(np.array([6, 47, 49, 15, 42, 41, 7, 39, 43, 40, 36])
    print("æ•°æ®æ ¼å¼ï¼š")
    print(dt)
    print('Q1:', df.quantile(.25))
    print('Q2:', df.quantile(.5))
    print('Q3:', df.quantile(.75))

__è®¡ç®—ç»“æœ__

    Q1: 25.5
    Q2: 40.0
    Q3: 42.5

  ## æ€»ç»“ï¼š
  
   å’Œ NumPy ä¸€æ ·ï¼ŒPandas æœ‰ä¸¤ä¸ªéå¸¸é‡è¦çš„æ•°æ®ç»“æ„ï¼šSeries å’Œ DataFrameã€‚ä½¿ç”¨ Pandas å¯ä»¥ç›´æ¥ä» csv æˆ– xlsx ç­‰æ–‡ä»¶ä¸­å¯¼å…¥æ•°æ®ï¼Œä»¥åŠæœ€ç»ˆè¾“å‡ºåˆ° excel è¡¨ä¸­ã€‚
   
   Pandas åŒ…ä¸ NumPy å·¥å…·åº“é…åˆä½¿ç”¨å¯ä»¥å‘æŒ¥å·¨å¤§çš„å¨åŠ›ï¼Œæ­£æ˜¯æœ‰äº† Pandas å·¥å…·ï¼ŒPython åšæ•°æ®æŒ–æ˜æ‰å…·æœ‰ä¼˜åŠ¿ã€‚
  
  
  
