# sklearn中的数据集的划分

1、`留出法`："留出法" (hold-out)直接将数据集 D 划分为两个互斥的集合?其中一个 集合作为训练集 S，另一个作为测试集 T，在 S 上训练出模型后，用 T 来评估其测试误差，作为对泛化误差的估计.

2、`交叉验证`：采用留出法可能造成数据量不够和训练时数据不够随机的情况，所以引入交叉验证。

*   `留一法`：交叉验证法的一个特例，假定数据集 D 中包含 m 个样本，若令 k=m(样本数)，则为留一法，留一法不随随机样本划分影响，它将m个样本划分为m个子集，每个子集中只包含一个样本。

    *   `优点`：留一法中被实际评估的模型与期望评估的用 D 训练出的模型很相似.因此，留一法的评估结果往往被认为比较准确

    *   `缺点`：在数据集比较大时，训练 m 个模型的计算开销可能是难以忍受的。

    但是根据没有免费午餐定理，留一法的估计结果未必永远比其他评估方法准确。

3、`自助法（bootstrapping）`: 有放回的抽样，这会造成一部分样本会被抽到，一部分样本不会被抽到，那么不会抽到的概率约为 1/e ≈ 36.8% ，在没有出现在训练数据集的样本会被用于测试，这样的测试结果被称为 “外包估计”。

*   `优点`：自助法在数据集较小、难以有效划分训练/测试集时很有用;此外，自助法 能从初始数据集中产生多个不同的训练集，这对集成学习等方法有很大的好处. 

*   `缺点`：然而，自助法产生的数据集改变了初始数据集的分布，这会引入估计偏差.因此，在初始数据量足够时，留出法和交叉验证法更常用一些.

## sklearn中的数据划分方法

1、数据集划分方法——__K折交叉验证__：KFold，GroupKFold，StratifiedKFold

2、数据集划分方法——__留一法__：LeaveOneGroupOut，LeavePGroupsOut，LeaveOneOut，LeavePOut

3、数据集划分方法——__随机划分法__：ShuffleSplit，GroupShuffleSplit，StratifiedShuffleSplit

这几个只是用于数据的分组，如果想要进行交叉验证和获得验证分数，还是需要使用相应的函数如：__cross_validate__、__cross_val_score__ 等。


## 为什么要使用交叉验证？交叉验证的介绍

交叉验证是指在给定的建模样本中，拿出其中的大部分样本进行模型训练，生成模型，留小部分样本用刚建立的模型进行预测，并求这小部分样本的预测误差，记录它们的平方加和。这个过程一直进行，直到所有的样本都被预测了一次而且仅被预测一次，比较每组的预测误差，选取误差最小的那一组作为训练模型。


__交叉验证是在机器学习建立模型和验证模型参数时常用的办法。__ 交叉验证，顾名思义，就是重复的使用数据，把得到的样本数据进行切分，组合为不同的训练集和测试集，用训练集来训练模型，用测试集来评估模型预测的好坏。在此基础上可以得到多组不同的训练集和测试集，某次训练集中的某样本在下次可能成为测试集中的样本，即所谓“交叉”。　

那么什么时候才需要交叉验证呢？交叉验证用在数据不是很充足的时候。 __它的基本想法就是重复地使用数据：把给定的数据进行切分，将切分的数据集组合为训练集和测试集，在此基础上反复地进行训练、测试以及模型选择。__ 比如在我日常项目里面，对于普通适中问题，如果数据样本量小于一万条，我们就会采用交叉验证来训练优化选择模型。如果样本大于一万条的话，我们一般随机的把数据分成三份，一份为训练集（Training Set），一份为验证集（Validation Set），最后一份为测试集（Test Set）。用训练集来训练模型，用验证集来评估模型预测的好坏和选择模型及其对应的参数。把最终得到的模型再用于测试集，最终决定使用哪个模型以及对应参数。



## 交叉验证的作用

__交叉验证是用来估计预测误差的__，从而进行模型选择，这一点与AIC、BIC本质没有区别。但是AIC、BIC等准则是从统计理论中推导出来的，而交叉验证是完完全全基于给定的样本。


## PS 为什么需要验证集呢?

因为当我们只有训练集和测试集的时候，如果我们进行预测之后，我们想要得到更好的结果，那我们会选择调整参数，但是一旦我们调整参数得到更好的结果？那么模型一定会更好吗？不，因为此时关于测试集的知识会被“泄漏”到模型中，评估指标不再报告泛化性能。所以我们会引进验证集。


__交叉验证的目的是为了能有效地估计模型的泛化能力 (测试误差)，从而进行模型选择。__ 评估模型，然后通过的出来的准确率，我们再进行模型选择。

## 小结：

当我们的数据集小时，我们的数据无法满足模型的复杂度就会过拟合，使用交叉验证我们可以重复地使用数据：把给定的数据进行切分，将切分的数据集组合为训练集和测试集，在此基础上反复地进行训练、测试以及模型选择。相当于我们增加了我们的数据量(防止过拟合)。最后得到我们模型的准确率(性能)。

交叉验证的思路就是，把样本集中的大部分样本作为训练集，剩余的小部分样本用于预测，来验证分类模型的准确性。通过准确率，我们最终可以决定使用哪个模型以及对应参数。

## PS 不推荐交叉验证集和验证集使用同样的数据集

在交叉验证中不推荐交叉训练集和验证集视同同样的数据集，比如说我们有10000个样本，我们将6000个样本进行训练，余下的4000个样本作为我们的交叉验证集和验证集，这样我们是不推荐的。这样会导致数据泄露。

我们可以将我们将6000个样本进行训练，余下的2000个样本作为我们的交叉验证集，2000个样本作为我们的验证集，这是推荐的。

### 补充说明：

#### 为什么交叉验证可以给我带来避免过拟合的作用呢？

首先我们要知道，在进行训练我们的模型时，我们的模型的参数是会发生变化的，这个变化的参数不是我们可以指定的超参数的变化，而是模型内部参数的变化，所以在我们进行交叉验证时(以k=10折交叉验证为例)，我们的模型的会根据训练的数据的不同而发生改变，所以每组训练完毕，模型参数会更新到较优参数，所以我们的模型会被不断的优化，这就避免了过拟合的风险(因为我们的训练数据为10组了)

#### 接下来我会介绍我们在进行交叉验证时，什么参数会发生变化和参数变化的过程

1、以BaggingClassifier为例，直接get_params拿到的只是你的配置参数，每颗决策树的参数。它的参数在Attributes里面，你可以用model1.estimators_features_ 这样类似的方法拿所有的模型参数。而get_params拿的只是你可以配置的超参数。

    base_estimator_ : estimator
    The base estimator from which the ensemble is grown.

    estimators_ : list of estimators
    The collection of fitted base estimators.

    estimators_samples_ : list of arrays
    The subset of drawn samples for each base estimator.

    estimators_features_ : list of arrays
    The subset of drawn features for each base estimator.

    classes_ : array of shape = [n_classes]
    The classes labels.

    n_classes_ : int or list
    The number of classes.

    oob_score_ : float
    Score of the training dataset obtained using an out-of-bag estimate.

    oob_decision_function_ : array of shape = [n_samples, n_classes]
    Decision function computed with out-of-bag estimate on the training set. If n_estimators is small it might be possible that a data point was never left out during the bootstrap. In this case, oob_decision_function_ might contain NaN.


2、同时假设我们分了10组数据做交叉验证，10种组合可以迭代训练出10组模型参数，我们选择最好的一组模型参数作为最终结果就行了。每组训练完毕，模型参数会更新到较优参数。而训练前后不变的只是一些超参数，比如你决定GBDT配置5个决策树，这个训练前后不会变。



## 如果我们的交叉验证集误差较大，我们如何判断是方差还是偏差呢?

![Image_text](https://raw.githubusercontent.com/OneStepAndTwoSteps/data_mining_analysis/master/static/%E6%96%B9%E5%B7%AE%E3%80%81%E5%81%8F%E5%B7%AE/2.png)

对于训练集，当 𝑑(多项式次数) 较小时，模型拟合程度更低，误差较大;随着 𝑑 的增长(模型变复杂)，拟合程度提高，误差减小。 
对于交叉验证集，当 𝑑(多项式次数) 较小时，模型拟合程度低，误差较大;但是随着 𝑑 的增长， 误差呈现先减小后增大的趋势，转折点是我们的模型开始过拟合训练数据集的时候。 


__训练集误差和交叉验证集误差近似时:偏差/欠拟合__

__交叉验证集误差远大于训练集误差时:方差/过拟合__ 


-《[ps:什么是过拟合，什么是欠拟合？](https://github.com/OneStepAndTwoSteps/data_mining_analysis/blob/master/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%BF%87%E6%8B%9F%E5%90%88%E5%92%8C%E6%AC%A0%E6%8B%9F%E5%90%88.md)》


-《[ps:什么是偏差，什么是方差？](https://github.com/OneStepAndTwoSteps/data_mining_analysis/blob/master/%E6%96%B9%E5%B7%AE%E3%80%81%E5%81%8F%E5%B7%AE/readme.md)》

